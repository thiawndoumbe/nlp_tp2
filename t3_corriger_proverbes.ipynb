{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d582d91d",
   "metadata": {},
   "source": [
    "# Tâche 3 - Corriger des proverbes avec des *transformers*\n",
    "\n",
    "Tout comme pour le premier travail pratique, l'objectif de cette tâche est de corriger des proverbes. Cependant vous devrez choisir et utiliser des modèles transformers (2) pour identifier le mot à remplacer et choisir le meilleur mot à insérer en fonction du contexte du proverbe. \n",
    "\n",
    "\n",
    "Consignes : \n",
    "- Corriger un proverbe consiste à remplacer un verbe par l’un des mots proposés dans la liste. \n",
    "- Choix des modèles transformer: Vous devrez choisir 2 modèles, un pour faire l’analyse grammaticale (*POS tagging*) et l'autre pour choisir le mot à insérer dans le proverbe. Deux contraintes : a) pas de LLMs, et b) utilisez des modèles de HuggingFace qui peuvent traiter le français (ou qui sont multilingues). \n",
    "- Entraînement des modèles : Vous pouvez utiliser les modèles préentraînés sans modification. Me consulter en cas de doute.  \n",
    "- Segmentation : Ne pas segmenter un proverbe en sous-phrases. \n",
    "- Tokenisation et plongements de mots : Ceux des modèles utilisés. \n",
    "- Prétraitement et normalisation : Rien à faire. \n",
    "- Code : Utilisez le fichier ***t3_corriger_proverbes.ipynb*** (ce fichier) pour mener vos expérimentations. \n",
    "- Données : Évaluez la performance à l’aide du fichier ***data/t3_test_proverbes.json*** et faire l'analyse de vos résultats. \n",
    "- Question : Comment se compare l’approche retenue pour cette tâche par rapport à celle du Travail pratique #1?\n",
    "\n",
    "Vous pouvez ajouter au *notebook* toutes les cellules dont vous avez besoin pour votre code, vos explications ou la présentation de vos résultats. Vous pouvez également ajouter des sous-sections (par ex. des sous-sections 1.1, 1.2 etc.) si cela améliore la lisibilité.\n",
    "\n",
    "Notes :\n",
    "- Évitez les bouts de code trop longs ou trop complexes. Par exemple, il est difficile de comprendre 4-5 boucles ou conditions imbriquées. Si c'est le cas, définissez des sous-fonctions pour refactoriser et simplifier votre code. \n",
    "- Expliquez sommairement votre démarche.\n",
    "- Expliquez les choix que vous faites au niveau de la programmation et des modèles (si non trivial).\n",
    "- Analyser vos résultats. Indiquez ce que vous observez, si c'est bon ou non, si c'est surprenant, etc. \n",
    "- Une analyse quantitative et qualitative d'erreurs est intéressante et permet de mieux comprendre le comportement d'un modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ec4af",
   "metadata": {},
   "source": [
    "## Section 1 - Lecture du fichier de test \n",
    "\n",
    "Le fichier de test ***./data/t3_test_proverbes.json*** contient les proverbes modifiés, la liste de mots candidats et la bonne version du proverbe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e10ec998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_tests(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as fp:\n",
    "        test_data = json.load(fp)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee39d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fn = './data/t3_test_proverbes.json'  # Le fichier de test = À modifier selon votre configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1545378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = load_tests(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e80bd88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Masked</th>\n",
       "      <th>Word_list</th>\n",
       "      <th>Proverb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a beau mentir qui part de loin</td>\n",
       "      <td>[vient, revient]</td>\n",
       "      <td>a beau mentir qui vient de loin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a beau dormir qui vient de loin</td>\n",
       "      <td>[partir, mentir]</td>\n",
       "      <td>a beau mentir qui vient de loin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l’occasion forge le larron</td>\n",
       "      <td>[fait, occasion]</td>\n",
       "      <td>l’occasion fait le larron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>endors-toi, le ciel t’aidera</td>\n",
       "      <td>[bouge, aide]</td>\n",
       "      <td>aide-toi, le ciel t’aidera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aide-toi, le ciel t’aura</td>\n",
       "      <td>[aidera, aide]</td>\n",
       "      <td>aide-toi, le ciel t’aidera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ce que femme dit, dieu le veut</td>\n",
       "      <td>[dit, veut]</td>\n",
       "      <td>ce que femme veut, dieu le veut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ce que femme veut, dieu le souhaite</td>\n",
       "      <td>[dit, veut]</td>\n",
       "      <td>ce que femme veut, dieu le veut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bien mal acquis ne sait jamais</td>\n",
       "      <td>[profite, fait]</td>\n",
       "      <td>bien mal acquis ne profite jamais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bon ouvrier ne déplace pas ses outils</td>\n",
       "      <td>[fait, querelle]</td>\n",
       "      <td>bon ouvrier ne querelle pas ses outils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pour le fou, c’était tous les jours fête</td>\n",
       "      <td>[est, es]</td>\n",
       "      <td>pour le fou, c’est tous les jours fête</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dire et plaire, sont deux</td>\n",
       "      <td>[dire, faire]</td>\n",
       "      <td>dire et faire, sont deux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>manger et faire, sont deux</td>\n",
       "      <td>[dire, faire]</td>\n",
       "      <td>dire et faire, sont deux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mieux vaut prévenir que courir</td>\n",
       "      <td>[prévenir, guérir]</td>\n",
       "      <td>mieux vaut prévenir que guérir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mieux vaut dormir que guérir</td>\n",
       "      <td>[prévenir, guérir]</td>\n",
       "      <td>mieux vaut prévenir que guérir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>à qui dieu aide, nul ne peut être</td>\n",
       "      <td>[aide, nuire]</td>\n",
       "      <td>à qui dieu aide, nul ne peut nuire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>à qui dieu veut, nul ne peut nuire</td>\n",
       "      <td>[aide, nuire]</td>\n",
       "      <td>à qui dieu aide, nul ne peut nuire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>il faut le faire pour le croire</td>\n",
       "      <td>[voir, boire]</td>\n",
       "      <td>il faut le voir pour le croire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>il faut le voir pour le saisir</td>\n",
       "      <td>[boire, croire]</td>\n",
       "      <td>il faut le voir pour le croire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on ne mord pas le poisson qui est encore dans la mer</td>\n",
       "      <td>[vend, dit]</td>\n",
       "      <td>on ne vend pas le poisson qui est encore dans la mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>on ne vend pas le poisson qui navigue encore dans la mer</td>\n",
       "      <td>[est, nage]</td>\n",
       "      <td>on ne vend pas le poisson qui est encore dans la mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>le poisson mange par la tête</td>\n",
       "      <td>[pourrit, respire]</td>\n",
       "      <td>le poisson pourrit par la tête</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>repose-toi plutôt sans souper, que de te lever avec des dettes</td>\n",
       "      <td>[lève, couche]</td>\n",
       "      <td>couche-toi plutôt sans souper, que de te lever avec des dettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>couche-toi plutôt sans souper, que de te retrouver avec des dettes</td>\n",
       "      <td>[mettre, lever]</td>\n",
       "      <td>couche-toi plutôt sans souper, que de te lever avec des dettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>les montagnes ne se déplacent point, mais les hommes se rencontrent</td>\n",
       "      <td>[rencontrent, paient]</td>\n",
       "      <td>les montagnes ne se rencontrent point, mais les hommes se rencontrent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>les montagnes ne se rencontrent point, mais les hommes se déplacent</td>\n",
       "      <td>[rencontrent, battent]</td>\n",
       "      <td>les montagnes ne se rencontrent point, mais les hommes se rencontrent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>étudier peu, chasse beaucoup de maladies</td>\n",
       "      <td>[manger, parle]</td>\n",
       "      <td>manger peu, chasse beaucoup de maladies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Masked  \\\n",
       "0                                        a beau mentir qui part de loin   \n",
       "1                                       a beau dormir qui vient de loin   \n",
       "2                                            l’occasion forge le larron   \n",
       "3                                          endors-toi, le ciel t’aidera   \n",
       "4                                              aide-toi, le ciel t’aura   \n",
       "5                                        ce que femme dit, dieu le veut   \n",
       "6                                   ce que femme veut, dieu le souhaite   \n",
       "7                                        bien mal acquis ne sait jamais   \n",
       "8                                 bon ouvrier ne déplace pas ses outils   \n",
       "9                              pour le fou, c’était tous les jours fête   \n",
       "10                                            dire et plaire, sont deux   \n",
       "11                                           manger et faire, sont deux   \n",
       "12                                       mieux vaut prévenir que courir   \n",
       "13                                         mieux vaut dormir que guérir   \n",
       "14                                    à qui dieu aide, nul ne peut être   \n",
       "15                                   à qui dieu veut, nul ne peut nuire   \n",
       "16                                      il faut le faire pour le croire   \n",
       "17                                       il faut le voir pour le saisir   \n",
       "18                 on ne mord pas le poisson qui est encore dans la mer   \n",
       "19             on ne vend pas le poisson qui navigue encore dans la mer   \n",
       "20                                         le poisson mange par la tête   \n",
       "21       repose-toi plutôt sans souper, que de te lever avec des dettes   \n",
       "22   couche-toi plutôt sans souper, que de te retrouver avec des dettes   \n",
       "23  les montagnes ne se déplacent point, mais les hommes se rencontrent   \n",
       "24  les montagnes ne se rencontrent point, mais les hommes se déplacent   \n",
       "25                             étudier peu, chasse beaucoup de maladies   \n",
       "\n",
       "                 Word_list  \\\n",
       "0         [vient, revient]   \n",
       "1         [partir, mentir]   \n",
       "2         [fait, occasion]   \n",
       "3            [bouge, aide]   \n",
       "4           [aidera, aide]   \n",
       "5              [dit, veut]   \n",
       "6              [dit, veut]   \n",
       "7          [profite, fait]   \n",
       "8         [fait, querelle]   \n",
       "9                [est, es]   \n",
       "10           [dire, faire]   \n",
       "11           [dire, faire]   \n",
       "12      [prévenir, guérir]   \n",
       "13      [prévenir, guérir]   \n",
       "14           [aide, nuire]   \n",
       "15           [aide, nuire]   \n",
       "16           [voir, boire]   \n",
       "17         [boire, croire]   \n",
       "18             [vend, dit]   \n",
       "19             [est, nage]   \n",
       "20      [pourrit, respire]   \n",
       "21          [lève, couche]   \n",
       "22         [mettre, lever]   \n",
       "23   [rencontrent, paient]   \n",
       "24  [rencontrent, battent]   \n",
       "25         [manger, parle]   \n",
       "\n",
       "                                                                  Proverb  \n",
       "0                                         a beau mentir qui vient de loin  \n",
       "1                                         a beau mentir qui vient de loin  \n",
       "2                                               l’occasion fait le larron  \n",
       "3                                              aide-toi, le ciel t’aidera  \n",
       "4                                              aide-toi, le ciel t’aidera  \n",
       "5                                         ce que femme veut, dieu le veut  \n",
       "6                                         ce que femme veut, dieu le veut  \n",
       "7                                       bien mal acquis ne profite jamais  \n",
       "8                                  bon ouvrier ne querelle pas ses outils  \n",
       "9                                  pour le fou, c’est tous les jours fête  \n",
       "10                                               dire et faire, sont deux  \n",
       "11                                               dire et faire, sont deux  \n",
       "12                                         mieux vaut prévenir que guérir  \n",
       "13                                         mieux vaut prévenir que guérir  \n",
       "14                                     à qui dieu aide, nul ne peut nuire  \n",
       "15                                     à qui dieu aide, nul ne peut nuire  \n",
       "16                                         il faut le voir pour le croire  \n",
       "17                                         il faut le voir pour le croire  \n",
       "18                   on ne vend pas le poisson qui est encore dans la mer  \n",
       "19                   on ne vend pas le poisson qui est encore dans la mer  \n",
       "20                                         le poisson pourrit par la tête  \n",
       "21         couche-toi plutôt sans souper, que de te lever avec des dettes  \n",
       "22         couche-toi plutôt sans souper, que de te lever avec des dettes  \n",
       "23  les montagnes ne se rencontrent point, mais les hommes se rencontrent  \n",
       "24  les montagnes ne se rencontrent point, mais les hommes se rencontrent  \n",
       "25                                manger peu, chasse beaucoup de maladies  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_dataframe(test_proverbs):\n",
    "    return pd.DataFrame.from_dict(test_proverbs, orient='columns', dtype=None, columns=None)\n",
    "\n",
    "df = get_dataframe(tests)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b071c",
   "metadata": {},
   "source": [
    "## Section 2 - Code pour repérer les mots qui pourraient être remplacés dans un proverbe modifié\n",
    "\n",
    "Expliquez ici comment vous procédez pour identifier les mots d'un proverbe qui pourraient faire l'objet d'une substitution.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a818b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irina/anaconda/envs/NLP_TP2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at gilf/french-camembert-postag-model were not used when initializing CamembertForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/Users/irina/anaconda/envs/NLP_TP2/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gilf/french-camembert-postag-model\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"gilf/french-camembert-postag-model\")\n",
    "\n",
    "\n",
    "pos_tagger = pipeline(\"ner\", model=model, tokenizer = tokenizer, grouped_entities=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9436b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at gilf/french-camembert-postag-model were not used when initializing CamembertForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at gilf/french-camembert-postag-model were not used when initializing CamembertForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gilf/french-camembert-postag-model\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"gilf/french-camembert-postag-model\")\n",
    "\n",
    "pos_tagger = pipeline(\"ner\", model=\"gilf/french-camembert-postag-model\", aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ba3203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at gilf/french-camembert-postag-model were not used when initializing CamembertForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'V', 'score': np.float32(0.9944412), 'word': 'a', 'start': 0, 'end': 1}, {'entity_group': 'ADJ', 'score': np.float32(0.589934), 'word': 'beau', 'start': 1, 'end': 6}, {'entity_group': 'VINF', 'score': np.float32(0.96936554), 'word': 'mentir', 'start': 6, 'end': 13}, {'entity_group': 'PROREL', 'score': np.float32(0.9933494), 'word': 'qui', 'start': 13, 'end': 17}, {'entity_group': 'V', 'score': np.float32(0.99252725), 'word': 'part', 'start': 17, 'end': 22}, {'entity_group': 'P', 'score': np.float32(0.9994779), 'word': 'de', 'start': 22, 'end': 25}, {'entity_group': 'ADV', 'score': np.float32(0.9980952), 'word': 'loin', 'start': 25, 'end': 30}]\n",
      "[{'entity_group': 'V', 'score': np.float32(0.99494654), 'word': 'a', 'start': 0, 'end': 1}, {'entity_group': 'ADJ', 'score': np.float32(0.575452), 'word': 'beau', 'start': 1, 'end': 6}, {'entity_group': 'VINF', 'score': np.float32(0.9855913), 'word': 'dormir', 'start': 6, 'end': 13}, {'entity_group': 'PROREL', 'score': np.float32(0.99501896), 'word': 'qui', 'start': 13, 'end': 17}, {'entity_group': 'V', 'score': np.float32(0.9993049), 'word': 'vient', 'start': 17, 'end': 23}, {'entity_group': 'P', 'score': np.float32(0.9995472), 'word': 'de', 'start': 23, 'end': 26}, {'entity_group': 'ADV', 'score': np.float32(0.99860954), 'word': 'loin', 'start': 26, 'end': 31}]\n",
      "[{'entity_group': 'DET', 'score': np.float32(0.9992465), 'word': 'l', 'start': 0, 'end': 1}, {'entity_group': 'NC', 'score': np.float32(0.69348496), 'word': '’occasion', 'start': 1, 'end': 10}, {'entity_group': 'V', 'score': np.float32(0.6174825), 'word': 'forge', 'start': 10, 'end': 16}, {'entity_group': 'DET', 'score': np.float32(0.9988223), 'word': 'le', 'start': 16, 'end': 19}, {'entity_group': 'NC', 'score': np.float32(0.8994153), 'word': 'larron', 'start': 19, 'end': 26}]\n",
      "[{'entity_group': 'V', 'score': np.float32(0.24352692), 'word': 'en', 'start': 0, 'end': 2}, {'entity_group': 'VIMP', 'score': np.float32(0.28675207), 'word': 'dors-', 'start': 2, 'end': 7}, {'entity_group': 'CLO', 'score': np.float32(0.7803102), 'word': 'toi', 'start': 7, 'end': 10}, {'entity_group': 'NC', 'score': np.float32(0.78054076), 'word': ',', 'start': 10, 'end': 11}, {'entity_group': 'DET', 'score': np.float32(0.99948394), 'word': 'le', 'start': 11, 'end': 14}, {'entity_group': 'NC', 'score': np.float32(0.99945146), 'word': 'ciel', 'start': 14, 'end': 19}, {'entity_group': 'CLO', 'score': np.float32(0.98531276), 'word': 't', 'start': 19, 'end': 21}, {'entity_group': 'NC', 'score': np.float32(0.24384964), 'word': '’', 'start': 21, 'end': 22}, {'entity_group': 'V', 'score': np.float32(0.9989878), 'word': 'aidera', 'start': 22, 'end': 28}]\n",
      "[{'entity_group': 'V', 'score': np.float32(0.40141794), 'word': 'aide', 'start': 0, 'end': 4}, {'entity_group': 'VIMP', 'score': np.float32(0.37628013), 'word': '-', 'start': 4, 'end': 5}, {'entity_group': 'CLO', 'score': np.float32(0.71971226), 'word': 'toi', 'start': 5, 'end': 8}, {'entity_group': 'NC', 'score': np.float32(0.33308667), 'word': ',', 'start': 8, 'end': 9}, {'entity_group': 'DET', 'score': np.float32(0.99943584), 'word': 'le', 'start': 9, 'end': 12}, {'entity_group': 'NC', 'score': np.float32(0.99937916), 'word': 'ciel', 'start': 12, 'end': 17}, {'entity_group': 'CLO', 'score': np.float32(0.983631), 'word': 't', 'start': 17, 'end': 19}, {'entity_group': 'NC', 'score': np.float32(0.35976416), 'word': '’', 'start': 19, 'end': 20}, {'entity_group': 'V', 'score': np.float32(0.9960043), 'word': 'aura', 'start': 20, 'end': 24}]\n",
      "[{'entity_group': 'PRO', 'score': np.float32(0.9854071), 'word': 'ce', 'start': 0, 'end': 2}, {'entity_group': 'PROREL', 'score': np.float32(0.9951302), 'word': 'que', 'start': 2, 'end': 6}, {'entity_group': 'NC', 'score': np.float32(0.6944545), 'word': 'femme', 'start': 6, 'end': 12}, {'entity_group': 'V', 'score': np.float32(0.64007425), 'word': 'dit', 'start': 12, 'end': 16}, {'entity_group': 'PONCT', 'score': np.float32(0.65439284), 'word': ',', 'start': 16, 'end': 17}, {'entity_group': 'NC', 'score': np.float32(0.8075447), 'word': 'dieu', 'start': 17, 'end': 22}, {'entity_group': 'CLO', 'score': np.float32(0.98954695), 'word': 'le', 'start': 22, 'end': 25}, {'entity_group': 'V', 'score': np.float32(0.9968443), 'word': 'veut', 'start': 25, 'end': 30}]\n",
      "[{'entity_group': 'PRO', 'score': np.float32(0.98168117), 'word': 'ce', 'start': 0, 'end': 2}, {'entity_group': 'PROREL', 'score': np.float32(0.9956291), 'word': 'que', 'start': 2, 'end': 6}, {'entity_group': 'NC', 'score': np.float32(0.79572904), 'word': 'femme', 'start': 6, 'end': 12}, {'entity_group': 'V', 'score': np.float32(0.9983511), 'word': 'veut', 'start': 12, 'end': 17}, {'entity_group': 'PONCT', 'score': np.float32(0.3764751), 'word': ',', 'start': 17, 'end': 18}, {'entity_group': 'NC', 'score': np.float32(0.8169861), 'word': 'dieu', 'start': 18, 'end': 23}, {'entity_group': 'CLO', 'score': np.float32(0.98846465), 'word': 'le', 'start': 23, 'end': 26}, {'entity_group': 'V', 'score': np.float32(0.9964246), 'word': 'souhaite', 'start': 26, 'end': 35}]\n",
      "[{'entity_group': 'ADV', 'score': np.float32(0.99871933), 'word': 'bien mal', 'start': 0, 'end': 8}, {'entity_group': 'VPP', 'score': np.float32(0.9969868), 'word': 'acquis', 'start': 8, 'end': 15}, {'entity_group': 'ADV', 'score': np.float32(0.99850607), 'word': 'ne', 'start': 15, 'end': 18}, {'entity_group': 'V', 'score': np.float32(0.9991437), 'word': 'sait', 'start': 18, 'end': 23}, {'entity_group': 'ADV', 'score': np.float32(0.9991596), 'word': 'jamais', 'start': 23, 'end': 30}]\n",
      "[{'entity_group': 'ADJ', 'score': np.float32(0.9986959), 'word': 'bon', 'start': 0, 'end': 3}, {'entity_group': 'NC', 'score': np.float32(0.99365604), 'word': 'ouvrier', 'start': 3, 'end': 11}, {'entity_group': 'ADV', 'score': np.float32(0.99923825), 'word': 'ne', 'start': 11, 'end': 14}, {'entity_group': 'V', 'score': np.float32(0.997421), 'word': 'déplace', 'start': 14, 'end': 22}, {'entity_group': 'ADV', 'score': np.float32(0.9992512), 'word': 'pas', 'start': 22, 'end': 26}, {'entity_group': 'DET', 'score': np.float32(0.9995012), 'word': 'ses', 'start': 26, 'end': 30}, {'entity_group': 'NC', 'score': np.float32(0.9995403), 'word': 'outils', 'start': 30, 'end': 37}]\n",
      "[{'entity_group': 'P', 'score': np.float32(0.99950385), 'word': 'pour', 'start': 0, 'end': 4}, {'entity_group': 'DET', 'score': np.float32(0.9981135), 'word': 'le', 'start': 4, 'end': 7}, {'entity_group': 'ADJ', 'score': np.float32(0.9324485), 'word': 'fou', 'start': 7, 'end': 11}, {'entity_group': 'PONCT', 'score': np.float32(0.46157938), 'word': ',', 'start': 11, 'end': 12}, {'entity_group': 'CLS', 'score': np.float32(0.9986298), 'word': 'c', 'start': 12, 'end': 14}, {'entity_group': 'NC', 'score': np.float32(0.5490312), 'word': '’', 'start': 14, 'end': 15}, {'entity_group': 'V', 'score': np.float32(0.9991698), 'word': 'était', 'start': 15, 'end': 20}, {'entity_group': 'ADJ', 'score': np.float32(0.99911743), 'word': 'tous', 'start': 20, 'end': 25}, {'entity_group': 'DET', 'score': np.float32(0.9994887), 'word': 'les', 'start': 25, 'end': 29}, {'entity_group': 'NC', 'score': np.float32(0.7420635), 'word': 'jours fête', 'start': 29, 'end': 40}]\n",
      "[{'entity_group': 'VINF', 'score': np.float32(0.93706316), 'word': 'dire', 'start': 0, 'end': 4}, {'entity_group': 'CC', 'score': np.float32(0.99863774), 'word': 'et', 'start': 4, 'end': 7}, {'entity_group': 'VINF', 'score': np.float32(0.9702369), 'word': 'plaire', 'start': 7, 'end': 14}, {'entity_group': 'PONCT', 'score': np.float32(0.917829), 'word': ',', 'start': 14, 'end': 15}, {'entity_group': 'V', 'score': np.float32(0.99895406), 'word': 'sont', 'start': 15, 'end': 20}, {'entity_group': 'PRO', 'score': np.float32(0.63606644), 'word': 'deux', 'start': 20, 'end': 25}]\n",
      "[{'entity_group': 'VINF', 'score': np.float32(0.97526157), 'word': 'manger', 'start': 0, 'end': 6}, {'entity_group': 'CC', 'score': np.float32(0.99850637), 'word': 'et', 'start': 6, 'end': 9}, {'entity_group': 'VINF', 'score': np.float32(0.98831826), 'word': 'faire', 'start': 9, 'end': 15}, {'entity_group': 'PONCT', 'score': np.float32(0.89386183), 'word': ',', 'start': 15, 'end': 16}, {'entity_group': 'V', 'score': np.float32(0.99873), 'word': 'sont', 'start': 16, 'end': 21}, {'entity_group': 'PRO', 'score': np.float32(0.5191813), 'word': 'deux', 'start': 21, 'end': 26}]\n",
      "[{'entity_group': 'ADV', 'score': np.float32(0.9988825), 'word': 'mieux', 'start': 0, 'end': 5}, {'entity_group': 'V', 'score': np.float32(0.99875283), 'word': 'vaut', 'start': 5, 'end': 10}, {'entity_group': 'VINF', 'score': np.float32(0.9983304), 'word': 'prévenir', 'start': 10, 'end': 19}, {'entity_group': 'CS', 'score': np.float32(0.93362015), 'word': 'que', 'start': 19, 'end': 23}, {'entity_group': 'VINF', 'score': np.float32(0.99049336), 'word': 'courir', 'start': 23, 'end': 30}]\n",
      "[{'entity_group': 'ADV', 'score': np.float32(0.99884784), 'word': 'mieux', 'start': 0, 'end': 5}, {'entity_group': 'V', 'score': np.float32(0.9985868), 'word': 'vaut', 'start': 5, 'end': 10}, {'entity_group': 'VINF', 'score': np.float32(0.99707174), 'word': 'dormir', 'start': 10, 'end': 17}, {'entity_group': 'CS', 'score': np.float32(0.95980954), 'word': 'que', 'start': 17, 'end': 21}, {'entity_group': 'VINF', 'score': np.float32(0.9699866), 'word': 'guérir', 'start': 21, 'end': 28}]\n",
      "[{'entity_group': 'P', 'score': np.float32(0.99901974), 'word': 'à', 'start': 0, 'end': 1}, {'entity_group': 'PROREL', 'score': np.float32(0.8296958), 'word': 'qui', 'start': 1, 'end': 5}, {'entity_group': 'NC', 'score': np.float32(0.47875285), 'word': 'dieu', 'start': 5, 'end': 10}, {'entity_group': 'V', 'score': np.float32(0.8350349), 'word': 'aide', 'start': 10, 'end': 15}, {'entity_group': 'CC', 'score': np.float32(0.2479734), 'word': ',', 'start': 15, 'end': 16}, {'entity_group': 'PRO', 'score': np.float32(0.98866165), 'word': 'nul', 'start': 16, 'end': 20}, {'entity_group': 'ADV', 'score': np.float32(0.9992361), 'word': 'ne', 'start': 20, 'end': 23}, {'entity_group': 'V', 'score': np.float32(0.9993104), 'word': 'peut', 'start': 23, 'end': 28}, {'entity_group': 'VINF', 'score': np.float32(0.9988954), 'word': 'être', 'start': 28, 'end': 33}]\n",
      "[{'entity_group': 'P', 'score': np.float32(0.9990607), 'word': 'à', 'start': 0, 'end': 1}, {'entity_group': 'PROREL', 'score': np.float32(0.8153191), 'word': 'qui', 'start': 1, 'end': 5}, {'entity_group': 'NC', 'score': np.float32(0.22259234), 'word': 'dieu', 'start': 5, 'end': 10}, {'entity_group': 'V', 'score': np.float32(0.9992053), 'word': 'veut', 'start': 10, 'end': 15}, {'entity_group': 'PONCT', 'score': np.float32(0.4095037), 'word': ',', 'start': 15, 'end': 16}, {'entity_group': 'PRO', 'score': np.float32(0.98995984), 'word': 'nul', 'start': 16, 'end': 20}, {'entity_group': 'ADV', 'score': np.float32(0.9992349), 'word': 'ne', 'start': 20, 'end': 23}, {'entity_group': 'V', 'score': np.float32(0.99932384), 'word': 'peut', 'start': 23, 'end': 28}, {'entity_group': 'VINF', 'score': np.float32(0.99869627), 'word': 'nuire', 'start': 28, 'end': 34}]\n",
      "[{'entity_group': 'CLS', 'score': np.float32(0.9983192), 'word': 'il', 'start': 0, 'end': 2}, {'entity_group': 'V', 'score': np.float32(0.99934226), 'word': 'faut', 'start': 2, 'end': 7}, {'entity_group': 'CLO', 'score': np.float32(0.99032694), 'word': 'le', 'start': 7, 'end': 10}, {'entity_group': 'VINF', 'score': np.float32(0.9901894), 'word': 'faire', 'start': 10, 'end': 16}, {'entity_group': 'P', 'score': np.float32(0.99949944), 'word': 'pour', 'start': 16, 'end': 21}, {'entity_group': 'CLO', 'score': np.float32(0.9737038), 'word': 'le', 'start': 21, 'end': 24}, {'entity_group': 'VINF', 'score': np.float32(0.94878805), 'word': 'croire', 'start': 24, 'end': 31}]\n",
      "[{'entity_group': 'CLS', 'score': np.float32(0.9983224), 'word': 'il', 'start': 0, 'end': 2}, {'entity_group': 'V', 'score': np.float32(0.99935025), 'word': 'faut', 'start': 2, 'end': 7}, {'entity_group': 'CLO', 'score': np.float32(0.9924948), 'word': 'le', 'start': 7, 'end': 10}, {'entity_group': 'VINF', 'score': np.float32(0.9979394), 'word': 'voir', 'start': 10, 'end': 15}, {'entity_group': 'P', 'score': np.float32(0.9995454), 'word': 'pour', 'start': 15, 'end': 20}, {'entity_group': 'CLO', 'score': np.float32(0.99002683), 'word': 'le', 'start': 20, 'end': 23}, {'entity_group': 'VINF', 'score': np.float32(0.9975074), 'word': 'saisir', 'start': 23, 'end': 30}]\n",
      "[{'entity_group': 'CLS', 'score': np.float32(0.99862313), 'word': 'on', 'start': 0, 'end': 2}, {'entity_group': 'ADV', 'score': np.float32(0.99923885), 'word': 'ne', 'start': 2, 'end': 5}, {'entity_group': 'V', 'score': np.float32(0.9857071), 'word': 'mord', 'start': 5, 'end': 10}, {'entity_group': 'ADV', 'score': np.float32(0.99924904), 'word': 'pas', 'start': 10, 'end': 14}, {'entity_group': 'DET', 'score': np.float32(0.99956435), 'word': 'le', 'start': 14, 'end': 17}, {'entity_group': 'NC', 'score': np.float32(0.99950063), 'word': 'poisson', 'start': 17, 'end': 25}, {'entity_group': 'PROREL', 'score': np.float32(0.9982017), 'word': 'qui', 'start': 25, 'end': 29}, {'entity_group': 'V', 'score': np.float32(0.9993703), 'word': 'est', 'start': 29, 'end': 33}, {'entity_group': 'ADV', 'score': np.float32(0.9992557), 'word': 'encore', 'start': 33, 'end': 40}, {'entity_group': 'P', 'score': np.float32(0.99961936), 'word': 'dans', 'start': 40, 'end': 45}, {'entity_group': 'DET', 'score': np.float32(0.99958986), 'word': 'la', 'start': 45, 'end': 48}, {'entity_group': 'NC', 'score': np.float32(0.99951303), 'word': 'mer', 'start': 48, 'end': 52}]\n",
      "[{'entity_group': 'CLS', 'score': np.float32(0.9986469), 'word': 'on', 'start': 0, 'end': 2}, {'entity_group': 'ADV', 'score': np.float32(0.9992487), 'word': 'ne', 'start': 2, 'end': 5}, {'entity_group': 'V', 'score': np.float32(0.9993286), 'word': 'vend', 'start': 5, 'end': 10}, {'entity_group': 'ADV', 'score': np.float32(0.99924785), 'word': 'pas', 'start': 10, 'end': 14}, {'entity_group': 'DET', 'score': np.float32(0.9995633), 'word': 'le', 'start': 14, 'end': 17}, {'entity_group': 'NC', 'score': np.float32(0.99949837), 'word': 'poisson', 'start': 17, 'end': 25}, {'entity_group': 'PROREL', 'score': np.float32(0.998206), 'word': 'qui', 'start': 25, 'end': 29}, {'entity_group': 'V', 'score': np.float32(0.9988136), 'word': 'navigue', 'start': 29, 'end': 37}, {'entity_group': 'ADV', 'score': np.float32(0.999257), 'word': 'encore', 'start': 37, 'end': 44}, {'entity_group': 'P', 'score': np.float32(0.99962115), 'word': 'dans', 'start': 44, 'end': 49}, {'entity_group': 'DET', 'score': np.float32(0.99959), 'word': 'la', 'start': 49, 'end': 52}, {'entity_group': 'NC', 'score': np.float32(0.99948883), 'word': 'mer', 'start': 52, 'end': 56}]\n",
      "[{'entity_group': 'DET', 'score': np.float32(0.9993137), 'word': 'le', 'start': 0, 'end': 2}, {'entity_group': 'NC', 'score': np.float32(0.9964888), 'word': 'poisson', 'start': 2, 'end': 10}, {'entity_group': 'V', 'score': np.float32(0.90820205), 'word': 'mange', 'start': 10, 'end': 16}, {'entity_group': 'P', 'score': np.float32(0.9993081), 'word': 'par', 'start': 16, 'end': 20}, {'entity_group': 'DET', 'score': np.float32(0.99944395), 'word': 'la', 'start': 20, 'end': 23}, {'entity_group': 'NC', 'score': np.float32(0.98285276), 'word': 'tête', 'start': 23, 'end': 28}]\n",
      "[{'entity_group': 'V', 'score': np.float32(0.5111769), 'word': 'repose', 'start': 0, 'end': 6}, {'entity_group': 'VIMP', 'score': np.float32(0.38596418), 'word': '-', 'start': 6, 'end': 7}, {'entity_group': 'CLO', 'score': np.float32(0.9480341), 'word': 'toi', 'start': 7, 'end': 10}, {'entity_group': 'ADV', 'score': np.float32(0.9992337), 'word': 'plutôt', 'start': 10, 'end': 17}, {'entity_group': 'P', 'score': np.float32(0.99942327), 'word': 'sans', 'start': 17, 'end': 22}, {'entity_group': 'VINF', 'score': np.float32(0.4933484), 'word': 'souper', 'start': 22, 'end': 29}, {'entity_group': 'PONCT', 'score': np.float32(0.5371981), 'word': ',', 'start': 29, 'end': 30}, {'entity_group': 'CS', 'score': np.float32(0.9907477), 'word': 'que', 'start': 30, 'end': 34}, {'entity_group': 'P', 'score': np.float32(0.9993679), 'word': 'de', 'start': 34, 'end': 37}, {'entity_group': 'CLO', 'score': np.float32(0.9896848), 'word': 'te', 'start': 37, 'end': 40}, {'entity_group': 'VINF', 'score': np.float32(0.99890995), 'word': 'lever', 'start': 40, 'end': 46}, {'entity_group': 'P', 'score': np.float32(0.99961436), 'word': 'avec', 'start': 46, 'end': 51}, {'entity_group': 'DET', 'score': np.float32(0.9995571), 'word': 'des', 'start': 51, 'end': 55}, {'entity_group': 'NC', 'score': np.float32(0.99951315), 'word': 'dettes', 'start': 55, 'end': 62}]\n",
      "[{'entity_group': 'V', 'score': np.float32(0.4327547), 'word': 'couche', 'start': 0, 'end': 6}, {'entity_group': 'VIMP', 'score': np.float32(0.40786883), 'word': '-', 'start': 6, 'end': 7}, {'entity_group': 'CLO', 'score': np.float32(0.9561925), 'word': 'toi', 'start': 7, 'end': 10}, {'entity_group': 'ADV', 'score': np.float32(0.9992255), 'word': 'plutôt', 'start': 10, 'end': 17}, {'entity_group': 'P', 'score': np.float32(0.99921894), 'word': 'sans', 'start': 17, 'end': 22}, {'entity_group': 'VINF', 'score': np.float32(0.4828611), 'word': 'souper', 'start': 22, 'end': 29}, {'entity_group': 'PONCT', 'score': np.float32(0.57764816), 'word': ',', 'start': 29, 'end': 30}, {'entity_group': 'CS', 'score': np.float32(0.99158657), 'word': 'que', 'start': 30, 'end': 34}, {'entity_group': 'P', 'score': np.float32(0.9993482), 'word': 'de', 'start': 34, 'end': 37}, {'entity_group': 'CLO', 'score': np.float32(0.98927337), 'word': 'te', 'start': 37, 'end': 40}, {'entity_group': 'VINF', 'score': np.float32(0.99890244), 'word': 'retrouver', 'start': 40, 'end': 50}, {'entity_group': 'P', 'score': np.float32(0.9996153), 'word': 'avec', 'start': 50, 'end': 55}, {'entity_group': 'DET', 'score': np.float32(0.99956316), 'word': 'des', 'start': 55, 'end': 59}, {'entity_group': 'NC', 'score': np.float32(0.9995111), 'word': 'dettes', 'start': 59, 'end': 66}]\n",
      "[{'entity_group': 'DET', 'score': np.float32(0.9995307), 'word': 'les', 'start': 0, 'end': 3}, {'entity_group': 'NC', 'score': np.float32(0.99950945), 'word': 'montagnes', 'start': 3, 'end': 13}, {'entity_group': 'ADV', 'score': np.float32(0.9992494), 'word': 'ne', 'start': 13, 'end': 16}, {'entity_group': 'CLR', 'score': np.float32(0.99830186), 'word': 'se', 'start': 16, 'end': 19}, {'entity_group': 'V', 'score': np.float32(0.9992974), 'word': 'déplacent', 'start': 19, 'end': 29}, {'entity_group': 'ADV', 'score': np.float32(0.99915314), 'word': 'point', 'start': 29, 'end': 35}, {'entity_group': 'PONCT', 'score': np.float32(0.9573973), 'word': ',', 'start': 35, 'end': 36}, {'entity_group': 'CC', 'score': np.float32(0.9991233), 'word': 'mais', 'start': 36, 'end': 41}, {'entity_group': 'DET', 'score': np.float32(0.99954164), 'word': 'les', 'start': 41, 'end': 45}, {'entity_group': 'NC', 'score': np.float32(0.9995566), 'word': 'hommes', 'start': 45, 'end': 52}, {'entity_group': 'CLR', 'score': np.float32(0.99826187), 'word': 'se', 'start': 52, 'end': 55}, {'entity_group': 'V', 'score': np.float32(0.99929845), 'word': 'rencontrent', 'start': 55, 'end': 67}]\n",
      "[{'entity_group': 'DET', 'score': np.float32(0.99952996), 'word': 'les', 'start': 0, 'end': 3}, {'entity_group': 'NC', 'score': np.float32(0.9995023), 'word': 'montagnes', 'start': 3, 'end': 13}, {'entity_group': 'ADV', 'score': np.float32(0.9992471), 'word': 'ne', 'start': 13, 'end': 16}, {'entity_group': 'CLR', 'score': np.float32(0.9982967), 'word': 'se', 'start': 16, 'end': 19}, {'entity_group': 'V', 'score': np.float32(0.9993156), 'word': 'rencontrent', 'start': 19, 'end': 31}, {'entity_group': 'ADV', 'score': np.float32(0.99915504), 'word': 'point', 'start': 31, 'end': 37}, {'entity_group': 'PONCT', 'score': np.float32(0.9505776), 'word': ',', 'start': 37, 'end': 38}, {'entity_group': 'CC', 'score': np.float32(0.9991215), 'word': 'mais', 'start': 38, 'end': 43}, {'entity_group': 'DET', 'score': np.float32(0.9995426), 'word': 'les', 'start': 43, 'end': 47}, {'entity_group': 'NC', 'score': np.float32(0.99955565), 'word': 'hommes', 'start': 47, 'end': 54}, {'entity_group': 'CLR', 'score': np.float32(0.9982381), 'word': 'se', 'start': 54, 'end': 57}, {'entity_group': 'V', 'score': np.float32(0.9992586), 'word': 'déplacent', 'start': 57, 'end': 67}]\n",
      "[{'entity_group': 'VINF', 'score': np.float32(0.99727446), 'word': 'étudier', 'start': 0, 'end': 7}, {'entity_group': 'ADV', 'score': np.float32(0.9991866), 'word': 'peu', 'start': 7, 'end': 11}, {'entity_group': 'CLO', 'score': np.float32(0.34129792), 'word': ',', 'start': 11, 'end': 12}, {'entity_group': 'NC', 'score': np.float32(0.74188125), 'word': 'chasse', 'start': 12, 'end': 19}, {'entity_group': 'ADV', 'score': np.float32(0.999035), 'word': 'beaucoup', 'start': 19, 'end': 28}, {'entity_group': 'P', 'score': np.float32(0.99936503), 'word': 'de', 'start': 28, 'end': 31}, {'entity_group': 'NC', 'score': np.float32(0.99900144), 'word': 'maladies', 'start': 31, 'end': 40}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Masked</th>\n",
       "      <th>Word_list</th>\n",
       "      <th>Proverb</th>\n",
       "      <th>verbes_in_masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a beau mentir qui part de loin</td>\n",
       "      <td>[vient, revient]</td>\n",
       "      <td>a beau mentir qui vient de loin</td>\n",
       "      <td>[a, mentir, part]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a beau dormir qui vient de loin</td>\n",
       "      <td>[partir, mentir]</td>\n",
       "      <td>a beau mentir qui vient de loin</td>\n",
       "      <td>[a, dormir, vient]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l’occasion forge le larron</td>\n",
       "      <td>[fait, occasion]</td>\n",
       "      <td>l’occasion fait le larron</td>\n",
       "      <td>[forge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>endors-toi, le ciel t’aidera</td>\n",
       "      <td>[bouge, aide]</td>\n",
       "      <td>aide-toi, le ciel t’aidera</td>\n",
       "      <td>[en, dors-, aidera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aide-toi, le ciel t’aura</td>\n",
       "      <td>[aidera, aide]</td>\n",
       "      <td>aide-toi, le ciel t’aidera</td>\n",
       "      <td>[aide, -, aura]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ce que femme dit, dieu le veut</td>\n",
       "      <td>[dit, veut]</td>\n",
       "      <td>ce que femme veut, dieu le veut</td>\n",
       "      <td>[dit, veut]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ce que femme veut, dieu le souhaite</td>\n",
       "      <td>[dit, veut]</td>\n",
       "      <td>ce que femme veut, dieu le veut</td>\n",
       "      <td>[veut, souhaite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bien mal acquis ne sait jamais</td>\n",
       "      <td>[profite, fait]</td>\n",
       "      <td>bien mal acquis ne profite jamais</td>\n",
       "      <td>[acquis, sait]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bon ouvrier ne déplace pas ses outils</td>\n",
       "      <td>[fait, querelle]</td>\n",
       "      <td>bon ouvrier ne querelle pas ses outils</td>\n",
       "      <td>[déplace]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pour le fou, c’était tous les jours fête</td>\n",
       "      <td>[est, es]</td>\n",
       "      <td>pour le fou, c’est tous les jours fête</td>\n",
       "      <td>[était]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dire et plaire, sont deux</td>\n",
       "      <td>[dire, faire]</td>\n",
       "      <td>dire et faire, sont deux</td>\n",
       "      <td>[dire, plaire, sont]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>manger et faire, sont deux</td>\n",
       "      <td>[dire, faire]</td>\n",
       "      <td>dire et faire, sont deux</td>\n",
       "      <td>[manger, faire, sont]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mieux vaut prévenir que courir</td>\n",
       "      <td>[prévenir, guérir]</td>\n",
       "      <td>mieux vaut prévenir que guérir</td>\n",
       "      <td>[vaut, prévenir, courir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mieux vaut dormir que guérir</td>\n",
       "      <td>[prévenir, guérir]</td>\n",
       "      <td>mieux vaut prévenir que guérir</td>\n",
       "      <td>[vaut, dormir, guérir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>à qui dieu aide, nul ne peut être</td>\n",
       "      <td>[aide, nuire]</td>\n",
       "      <td>à qui dieu aide, nul ne peut nuire</td>\n",
       "      <td>[aide, peut, être]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>à qui dieu veut, nul ne peut nuire</td>\n",
       "      <td>[aide, nuire]</td>\n",
       "      <td>à qui dieu aide, nul ne peut nuire</td>\n",
       "      <td>[veut, peut, nuire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>il faut le faire pour le croire</td>\n",
       "      <td>[voir, boire]</td>\n",
       "      <td>il faut le voir pour le croire</td>\n",
       "      <td>[faut, faire, croire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>il faut le voir pour le saisir</td>\n",
       "      <td>[boire, croire]</td>\n",
       "      <td>il faut le voir pour le croire</td>\n",
       "      <td>[faut, voir, saisir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on ne mord pas le poisson qui est encore dans ...</td>\n",
       "      <td>[vend, dit]</td>\n",
       "      <td>on ne vend pas le poisson qui est encore dans ...</td>\n",
       "      <td>[mord, est]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>on ne vend pas le poisson qui navigue encore d...</td>\n",
       "      <td>[est, nage]</td>\n",
       "      <td>on ne vend pas le poisson qui est encore dans ...</td>\n",
       "      <td>[vend, navigue]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>le poisson mange par la tête</td>\n",
       "      <td>[pourrit, respire]</td>\n",
       "      <td>le poisson pourrit par la tête</td>\n",
       "      <td>[mange]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>repose-toi plutôt sans souper, que de te lever...</td>\n",
       "      <td>[lève, couche]</td>\n",
       "      <td>couche-toi plutôt sans souper, que de te lever...</td>\n",
       "      <td>[repose, -, souper, lever]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>couche-toi plutôt sans souper, que de te retro...</td>\n",
       "      <td>[mettre, lever]</td>\n",
       "      <td>couche-toi plutôt sans souper, que de te lever...</td>\n",
       "      <td>[couche, -, souper, retrouver]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>les montagnes ne se déplacent point, mais les ...</td>\n",
       "      <td>[rencontrent, paient]</td>\n",
       "      <td>les montagnes ne se rencontrent point, mais le...</td>\n",
       "      <td>[déplacent, rencontrent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>les montagnes ne se rencontrent point, mais le...</td>\n",
       "      <td>[rencontrent, battent]</td>\n",
       "      <td>les montagnes ne se rencontrent point, mais le...</td>\n",
       "      <td>[rencontrent, déplacent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>étudier peu, chasse beaucoup de maladies</td>\n",
       "      <td>[manger, parle]</td>\n",
       "      <td>manger peu, chasse beaucoup de maladies</td>\n",
       "      <td>[étudier]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Masked               Word_list  \\\n",
       "0                      a beau mentir qui part de loin        [vient, revient]   \n",
       "1                     a beau dormir qui vient de loin        [partir, mentir]   \n",
       "2                          l’occasion forge le larron        [fait, occasion]   \n",
       "3                        endors-toi, le ciel t’aidera           [bouge, aide]   \n",
       "4                            aide-toi, le ciel t’aura          [aidera, aide]   \n",
       "5                      ce que femme dit, dieu le veut             [dit, veut]   \n",
       "6                 ce que femme veut, dieu le souhaite             [dit, veut]   \n",
       "7                      bien mal acquis ne sait jamais         [profite, fait]   \n",
       "8               bon ouvrier ne déplace pas ses outils        [fait, querelle]   \n",
       "9            pour le fou, c’était tous les jours fête               [est, es]   \n",
       "10                          dire et plaire, sont deux           [dire, faire]   \n",
       "11                         manger et faire, sont deux           [dire, faire]   \n",
       "12                     mieux vaut prévenir que courir      [prévenir, guérir]   \n",
       "13                       mieux vaut dormir que guérir      [prévenir, guérir]   \n",
       "14                  à qui dieu aide, nul ne peut être           [aide, nuire]   \n",
       "15                 à qui dieu veut, nul ne peut nuire           [aide, nuire]   \n",
       "16                    il faut le faire pour le croire           [voir, boire]   \n",
       "17                     il faut le voir pour le saisir         [boire, croire]   \n",
       "18  on ne mord pas le poisson qui est encore dans ...             [vend, dit]   \n",
       "19  on ne vend pas le poisson qui navigue encore d...             [est, nage]   \n",
       "20                       le poisson mange par la tête      [pourrit, respire]   \n",
       "21  repose-toi plutôt sans souper, que de te lever...          [lève, couche]   \n",
       "22  couche-toi plutôt sans souper, que de te retro...         [mettre, lever]   \n",
       "23  les montagnes ne se déplacent point, mais les ...   [rencontrent, paient]   \n",
       "24  les montagnes ne se rencontrent point, mais le...  [rencontrent, battent]   \n",
       "25           étudier peu, chasse beaucoup de maladies         [manger, parle]   \n",
       "\n",
       "                                              Proverb  \\\n",
       "0                     a beau mentir qui vient de loin   \n",
       "1                     a beau mentir qui vient de loin   \n",
       "2                           l’occasion fait le larron   \n",
       "3                          aide-toi, le ciel t’aidera   \n",
       "4                          aide-toi, le ciel t’aidera   \n",
       "5                     ce que femme veut, dieu le veut   \n",
       "6                     ce que femme veut, dieu le veut   \n",
       "7                   bien mal acquis ne profite jamais   \n",
       "8              bon ouvrier ne querelle pas ses outils   \n",
       "9              pour le fou, c’est tous les jours fête   \n",
       "10                           dire et faire, sont deux   \n",
       "11                           dire et faire, sont deux   \n",
       "12                     mieux vaut prévenir que guérir   \n",
       "13                     mieux vaut prévenir que guérir   \n",
       "14                 à qui dieu aide, nul ne peut nuire   \n",
       "15                 à qui dieu aide, nul ne peut nuire   \n",
       "16                     il faut le voir pour le croire   \n",
       "17                     il faut le voir pour le croire   \n",
       "18  on ne vend pas le poisson qui est encore dans ...   \n",
       "19  on ne vend pas le poisson qui est encore dans ...   \n",
       "20                     le poisson pourrit par la tête   \n",
       "21  couche-toi plutôt sans souper, que de te lever...   \n",
       "22  couche-toi plutôt sans souper, que de te lever...   \n",
       "23  les montagnes ne se rencontrent point, mais le...   \n",
       "24  les montagnes ne se rencontrent point, mais le...   \n",
       "25            manger peu, chasse beaucoup de maladies   \n",
       "\n",
       "                  verbes_in_masked  \n",
       "0                [a, mentir, part]  \n",
       "1               [a, dormir, vient]  \n",
       "2                          [forge]  \n",
       "3              [en, dors-, aidera]  \n",
       "4                  [aide, -, aura]  \n",
       "5                      [dit, veut]  \n",
       "6                 [veut, souhaite]  \n",
       "7                   [acquis, sait]  \n",
       "8                        [déplace]  \n",
       "9                          [était]  \n",
       "10            [dire, plaire, sont]  \n",
       "11           [manger, faire, sont]  \n",
       "12        [vaut, prévenir, courir]  \n",
       "13          [vaut, dormir, guérir]  \n",
       "14              [aide, peut, être]  \n",
       "15             [veut, peut, nuire]  \n",
       "16           [faut, faire, croire]  \n",
       "17            [faut, voir, saisir]  \n",
       "18                     [mord, est]  \n",
       "19                 [vend, navigue]  \n",
       "20                         [mange]  \n",
       "21      [repose, -, souper, lever]  \n",
       "22  [couche, -, souper, retrouver]  \n",
       "23        [déplacent, rencontrent]  \n",
       "24        [rencontrent, déplacent]  \n",
       "25                       [étudier]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gilf/french-camembert-postag-model\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"gilf/french-camembert-postag-model\")\n",
    "\n",
    "pos_tagger = pipeline(\"ner\", model=model, tokenizer = tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "def get_verbs(phrase):\n",
    "    tags = pos_tagger(phrase)\n",
    "    print(tags)\n",
    "    verbes = [tag['word'] for tag in tags if tag['entity_group'] in ['V', 'VIMP', 'VINF', 'V', 'VPP', 'VR', 'VS' ]]\n",
    "    return verbes\n",
    "\n",
    "df['verbes_in_masked'] = df['Masked'].apply(get_verbs)\n",
    "print(df.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "964cfa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index                        masked_sentence         word_list  \\\n",
      "0       0    <mask> beau mentir qui part de loin  [vient, revient]   \n",
      "1       0         a beau <mask> qui part de loin  [vient, revient]   \n",
      "2       0       a beau mentir qui <mask> de loin  [vient, revient]   \n",
      "3       1   <mask> beau dormir qui vient de loin  [partir, mentir]   \n",
      "4       1        a beau <mask> qui vient de loin  [partir, mentir]   \n",
      "5       1       a beau dormir qui <mask> de loin  [partir, mentir]   \n",
      "6       2            l’occasion <mask> le larron  [fait, occasion]   \n",
      "7       3           endors-toi, le ciel t’aidera     [bouge, aide]   \n",
      "8       3           endors-toi, le ciel t’aidera     [bouge, aide]   \n",
      "9       3           endors-toi, le ciel t’<mask>     [bouge, aide]   \n",
      "10      4             <mask>-toi, le ciel t’aura    [aidera, aide]   \n",
      "11      4          aide<mask>toi, le ciel t’aura    [aidera, aide]   \n",
      "12      4             aide-toi, le ciel t’<mask>    [aidera, aide]   \n",
      "13      5      ce que femme <mask>, dieu le veut       [dit, veut]   \n",
      "14      5       ce que femme dit, dieu le <mask>       [dit, veut]   \n",
      "15      6  ce que femme <mask>, dieu le souhaite       [dit, veut]   \n",
      "16      6      ce que femme veut, dieu le <mask>       [dit, veut]   \n",
      "17      7         bien mal <mask> ne sait jamais   [profite, fait]   \n",
      "18      7       bien mal acquis ne <mask> jamais   [profite, fait]   \n",
      "19      8   bon ouvrier ne <mask> pas ses outils  [fait, querelle]   \n",
      "\n",
      "                  original_masked_proverb  \\\n",
      "0          a beau mentir qui part de loin   \n",
      "1          a beau mentir qui part de loin   \n",
      "2          a beau mentir qui part de loin   \n",
      "3         a beau dormir qui vient de loin   \n",
      "4         a beau dormir qui vient de loin   \n",
      "5         a beau dormir qui vient de loin   \n",
      "6              l’occasion forge le larron   \n",
      "7            endors-toi, le ciel t’aidera   \n",
      "8            endors-toi, le ciel t’aidera   \n",
      "9            endors-toi, le ciel t’aidera   \n",
      "10               aide-toi, le ciel t’aura   \n",
      "11               aide-toi, le ciel t’aura   \n",
      "12               aide-toi, le ciel t’aura   \n",
      "13         ce que femme dit, dieu le veut   \n",
      "14         ce que femme dit, dieu le veut   \n",
      "15    ce que femme veut, dieu le souhaite   \n",
      "16    ce que femme veut, dieu le souhaite   \n",
      "17         bien mal acquis ne sait jamais   \n",
      "18         bien mal acquis ne sait jamais   \n",
      "19  bon ouvrier ne déplace pas ses outils   \n",
      "\n",
      "                              ground_truth  \n",
      "0          a beau mentir qui vient de loin  \n",
      "1          a beau mentir qui vient de loin  \n",
      "2          a beau mentir qui vient de loin  \n",
      "3          a beau mentir qui vient de loin  \n",
      "4          a beau mentir qui vient de loin  \n",
      "5          a beau mentir qui vient de loin  \n",
      "6                l’occasion fait le larron  \n",
      "7               aide-toi, le ciel t’aidera  \n",
      "8               aide-toi, le ciel t’aidera  \n",
      "9               aide-toi, le ciel t’aidera  \n",
      "10              aide-toi, le ciel t’aidera  \n",
      "11              aide-toi, le ciel t’aidera  \n",
      "12              aide-toi, le ciel t’aidera  \n",
      "13         ce que femme veut, dieu le veut  \n",
      "14         ce que femme veut, dieu le veut  \n",
      "15         ce que femme veut, dieu le veut  \n",
      "16         ce que femme veut, dieu le veut  \n",
      "17       bien mal acquis ne profite jamais  \n",
      "18       bien mal acquis ne profite jamais  \n",
      "19  bon ouvrier ne querelle pas ses outils  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# new dataframe with only one word masked per observation - index indicates old observation \n",
    "new_rows = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    original_sentence = row['Masked']\n",
    "    for verb in row['verbes_in_masked']:\n",
    "        masked_sentence = re.sub(rf'\\b{re.escape(verb)}\\b', '<mask>', original_sentence)\n",
    "        new_rows.append({\n",
    "            'index': idx,  # Shared index\n",
    "            'masked_sentence': masked_sentence,\n",
    "            'word_list': row['Word_list'],  # Word candidates\n",
    "            'original_masked_proverb': row['Masked'],  # Original masked proverb for reference\n",
    "            'ground_truth': row['Proverb']\n",
    "        })\n",
    "\n",
    "# new dataframe\n",
    "masked_df = pd.DataFrame(new_rows)\n",
    "print(masked_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbe9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c57364c",
   "metadata": {},
   "source": [
    "## Section 3 - Modèle et code pour corriger un proverbe\n",
    "\n",
    "Expliquez ici comment vous procédez pour choisir la meilleure version parmi les proverbes modifiés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d4c6390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert/camembert-base-oscar-4gb\")\n",
    "camembert = CamembertModel.from_pretrained(\"camembert/camembert-base-oscar-4gb\")\n",
    "\n",
    "camembert_fill_mask  = pipeline(\"fill-mask\", model=\"camembert/camembert-base-oscar-4gb\", tokenizer=\"camembert/camembert-base-oscar-4gb\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e460425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The specified target token `revient` does not exist in the model vocabulary. Replacing with `▁revient`.\n",
      "The specified target token `revient` does not exist in the model vocabulary. Replacing with `▁revient`.\n",
      "The specified target token `revient` does not exist in the model vocabulary. Replacing with `▁revient`.\n",
      "The specified target token `partir` does not exist in the model vocabulary. Replacing with `▁partir`.\n",
      "The specified target token `mentir` does not exist in the model vocabulary. Replacing with `▁mentir`.\n",
      "The specified target token `partir` does not exist in the model vocabulary. Replacing with `▁partir`.\n",
      "The specified target token `mentir` does not exist in the model vocabulary. Replacing with `▁mentir`.\n",
      "The specified target token `partir` does not exist in the model vocabulary. Replacing with `▁partir`.\n",
      "The specified target token `mentir` does not exist in the model vocabulary. Replacing with `▁mentir`.\n",
      "The specified target token `bouge` does not exist in the model vocabulary. Replacing with `▁bouge`.\n",
      "The specified target token `bouge` does not exist in the model vocabulary. Replacing with `▁bouge`.\n",
      "The specified target token `bouge` does not exist in the model vocabulary. Replacing with `▁bouge`.\n",
      "The specified target token `aidera` does not exist in the model vocabulary. Replacing with `▁aidera`.\n",
      "The specified target token `aidera` does not exist in the model vocabulary. Replacing with `▁aidera`.\n",
      "The specified target token `aidera` does not exist in the model vocabulary. Replacing with `▁aidera`.\n",
      "The specified target token `veut` does not exist in the model vocabulary. Replacing with `▁veut`.\n",
      "The specified target token `veut` does not exist in the model vocabulary. Replacing with `▁veut`.\n",
      "The specified target token `veut` does not exist in the model vocabulary. Replacing with `▁veut`.\n",
      "The specified target token `veut` does not exist in the model vocabulary. Replacing with `▁veut`.\n",
      "The specified target token `profite` does not exist in the model vocabulary. Replacing with `▁profite`.\n",
      "The specified target token `profite` does not exist in the model vocabulary. Replacing with `▁profite`.\n",
      "The specified target token `querelle` does not exist in the model vocabulary. Replacing with `▁querelle`.\n",
      "The specified target token `prévenir` does not exist in the model vocabulary. Replacing with `▁prévenir`.\n",
      "The specified target token `guérir` does not exist in the model vocabulary. Replacing with `▁guérir`.\n",
      "The specified target token `prévenir` does not exist in the model vocabulary. Replacing with `▁prévenir`.\n",
      "The specified target token `guérir` does not exist in the model vocabulary. Replacing with `▁guérir`.\n",
      "The specified target token `prévenir` does not exist in the model vocabulary. Replacing with `▁prévenir`.\n",
      "The specified target token `guérir` does not exist in the model vocabulary. Replacing with `▁guérir`.\n",
      "The specified target token `prévenir` does not exist in the model vocabulary. Replacing with `▁prévenir`.\n",
      "The specified target token `guérir` does not exist in the model vocabulary. Replacing with `▁guérir`.\n",
      "The specified target token `prévenir` does not exist in the model vocabulary. Replacing with `▁prévenir`.\n",
      "The specified target token `guérir` does not exist in the model vocabulary. Replacing with `▁guérir`.\n",
      "The specified target token `prévenir` does not exist in the model vocabulary. Replacing with `▁prévenir`.\n",
      "The specified target token `guérir` does not exist in the model vocabulary. Replacing with `▁guérir`.\n",
      "The specified target token `nuire` does not exist in the model vocabulary. Replacing with `▁nuire`.\n",
      "The specified target token `nuire` does not exist in the model vocabulary. Replacing with `▁nuire`.\n",
      "The specified target token `nuire` does not exist in the model vocabulary. Replacing with `▁nuire`.\n",
      "The specified target token `nuire` does not exist in the model vocabulary. Replacing with `▁nuire`.\n",
      "The specified target token `nuire` does not exist in the model vocabulary. Replacing with `▁nuire`.\n",
      "The specified target token `nuire` does not exist in the model vocabulary. Replacing with `▁nuire`.\n",
      "The specified target token `boire` does not exist in the model vocabulary. Replacing with `▁boire`.\n",
      "The specified target token `boire` does not exist in the model vocabulary. Replacing with `▁boire`.\n",
      "The specified target token `boire` does not exist in the model vocabulary. Replacing with `▁boire`.\n",
      "The specified target token `boire` does not exist in the model vocabulary. Replacing with `▁boire`.\n",
      "The specified target token `croire` does not exist in the model vocabulary. Replacing with `▁croire`.\n",
      "The specified target token `boire` does not exist in the model vocabulary. Replacing with `▁boire`.\n",
      "The specified target token `croire` does not exist in the model vocabulary. Replacing with `▁croire`.\n",
      "The specified target token `boire` does not exist in the model vocabulary. Replacing with `▁boire`.\n",
      "The specified target token `croire` does not exist in the model vocabulary. Replacing with `▁croire`.\n",
      "The specified target token `vend` does not exist in the model vocabulary. Replacing with `▁vend`.\n",
      "The specified target token `vend` does not exist in the model vocabulary. Replacing with `▁vend`.\n",
      "The specified target token `pourrit` does not exist in the model vocabulary. Replacing with `▁pour`.\n",
      "The specified target token `respire` does not exist in the model vocabulary. Replacing with `▁respire`.\n",
      "The specified target token `rencontrent` does not exist in the model vocabulary. Replacing with `▁rencontrent`.\n",
      "The specified target token `paient` does not exist in the model vocabulary. Replacing with `▁paient`.\n",
      "The specified target token `rencontrent` does not exist in the model vocabulary. Replacing with `▁rencontrent`.\n",
      "The specified target token `paient` does not exist in the model vocabulary. Replacing with `▁paient`.\n",
      "The specified target token `rencontrent` does not exist in the model vocabulary. Replacing with `▁rencontrent`.\n",
      "The specified target token `battent` does not exist in the model vocabulary. Replacing with `▁battent`.\n",
      "The specified target token `rencontrent` does not exist in the model vocabulary. Replacing with `▁rencontrent`.\n",
      "The specified target token `battent` does not exist in the model vocabulary. Replacing with `▁battent`.\n",
      "The specified target token `manger` does not exist in the model vocabulary. Replacing with `▁manger`.\n",
      "The specified target token `parle` does not exist in the model vocabulary. Replacing with `▁parle`.\n"
     ]
    }
   ],
   "source": [
    "# Prediction function for masked sentences\n",
    "def make_predictions(row):\n",
    "    try:\n",
    "        return camembert_fill_mask(row['masked_sentence'], targets=row['word_list'])\n",
    "    except Exception as e:\n",
    "        # return error message in case something goes wrong\n",
    "        return str(e)\n",
    "\n",
    "# Applying it\n",
    "masked_df['predictions'] = masked_df.apply(make_predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5caf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                  [{'score': 5.756229626285858e-08, 'token': 2151, 'token_str': 'revient', 'sequence': 'revient beau mentir qui part de loin'}, {'score': 4.6352996996290585e-09, 'token': 17068, 'token_str': 'vient', 'sequence': 'vient beau mentir qui part de loin'}]\n",
      "1                                            [{'score': 1.6705618691048585e-05, 'token': 2151, 'token_str': 'revient', 'sequence': 'a beau revient qui part de loin'}, {'score': 4.7252122215013515e-08, 'token': 17068, 'token_str': 'vient', 'sequence': 'a beauvient qui part de loin'}]\n",
      "2                                            [{'score': 0.09831991046667099, 'token': 2151, 'token_str': 'revient', 'sequence': 'a beau mentir qui revient de loin'}, {'score': 8.770224724230502e-08, 'token': 17068, 'token_str': 'vient', 'sequence': 'a beau mentir quivient de loin'}]\n",
      "3                                [{'score': 3.5203133847971912e-06, 'token': 350, 'token_str': 'partir', 'sequence': 'partir beau dormir qui vient de loin'}, {'score': 2.0743095774378162e-07, 'token': 15839, 'token_str': 'mentir', 'sequence': 'mentir beau dormir qui vient de loin'}]\n",
      "4                                           [{'score': 0.00037340749986469746, 'token': 350, 'token_str': 'partir', 'sequence': 'a beau partir qui vient de loin'}, {'score': 2.420452619844582e-05, 'token': 15839, 'token_str': 'mentir', 'sequence': 'a beau mentir qui vient de loin'}]\n",
      "5                                         [{'score': 0.00019404859631322324, 'token': 350, 'token_str': 'partir', 'sequence': 'a beau dormir qui partir de loin'}, {'score': 1.685952383922995e-06, 'token': 15839, 'token_str': 'mentir', 'sequence': 'a beau dormir qui mentir de loin'}]\n",
      "6                                                     [{'score': 2.846029190095578e-07, 'token': 690, 'token_str': 'occasion', 'sequence': 'l’occasionoccasion le larron'}, {'score': 2.0510158904585296e-08, 'token': 10075, 'token_str': 'fait', 'sequence': 'l’occasionfait le larron'}]\n",
      "7                                                                                                                                                                                                                                                 No mask_token (<mask>) found on the input\n",
      "8                                                                                                                                                                                                                                                 No mask_token (<mask>) found on the input\n",
      "9                                                       [{'score': 1.208062030855217e-06, 'token': 6337, 'token_str': 'bouge', 'sequence': 'endors-toi, le ciel t’ bouge'}, {'score': 2.9202445261944376e-07, 'token': 761, 'token_str': 'aide', 'sequence': 'endors-toi, le ciel t’aide'}]\n",
      "10                                                      [{'score': 2.718517407629406e-06, 'token': 11611, 'token_str': 'aidera', 'sequence': 'aidera -toi, le ciel t’aura'}, {'score': 1.4959011878090678e-06, 'token': 761, 'token_str': 'aide', 'sequence': 'aide -toi, le ciel t’aura'}]\n",
      "11                                               [{'score': 3.326308069517836e-05, 'token': 11611, 'token_str': 'aidera', 'sequence': 'aide aidera toi, le ciel t’aura'}, {'score': 1.7881349094750476e-06, 'token': 761, 'token_str': 'aide', 'sequence': 'aideaide toi, le ciel t’aura'}]\n",
      "12                                                          [{'score': 0.49035122990608215, 'token': 11611, 'token_str': 'aidera', 'sequence': 'aide-toi, le ciel t’ aidera'}, {'score': 5.284612598188687e-06, 'token': 761, 'token_str': 'aide', 'sequence': 'aide-toi, le ciel t’aide'}]\n",
      "13                                                     [{'score': 0.606407105922699, 'token': 604, 'token_str': 'veut', 'sequence': 'ce que femme veut , dieu le veut'}, {'score': 8.044887422897773e-09, 'token': 3249, 'token_str': 'dit', 'sequence': 'ce que femmedit , dieu le veut'}]\n",
      "14                                                      [{'score': 0.015887435525655746, 'token': 604, 'token_str': 'veut', 'sequence': 'ce que femme dit, dieu le veut'}, {'score': 3.953695704694837e-05, 'token': 3249, 'token_str': 'dit', 'sequence': 'ce que femme dit, dieu ledit'}]\n",
      "15                                            [{'score': 0.14708244800567627, 'token': 604, 'token_str': 'veut', 'sequence': 'ce que femme veut , dieu le souhaite'}, {'score': 5.64249491574742e-09, 'token': 3249, 'token_str': 'dit', 'sequence': 'ce que femmedit , dieu le souhaite'}]\n",
      "16                                                    [{'score': 0.20613674819469452, 'token': 604, 'token_str': 'veut', 'sequence': 'ce que femme veut, dieu le veut'}, {'score': 1.5937891930661863e-06, 'token': 3249, 'token_str': 'dit', 'sequence': 'ce que femme veut, dieu ledit'}]\n",
      "17                                               [{'score': 2.283759204146918e-05, 'token': 4555, 'token_str': 'profite', 'sequence': 'bien mal profite ne sait jamais'}, {'score': 4.526722818809503e-07, 'token': 10075, 'token_str': 'fait', 'sequence': 'bien malfait ne sait jamais'}]\n",
      "18                                           [{'score': 0.010499415919184685, 'token': 4555, 'token_str': 'profite', 'sequence': 'bien mal acquis ne profite jamais'}, {'score': 1.2807255416191765e-06, 'token': 10075, 'token_str': 'fait', 'sequence': 'bien mal acquis nefait jamais'}]\n",
      "19                                [{'score': 4.601278760674177e-06, 'token': 21842, 'token_str': 'querelle', 'sequence': 'bon ouvrier ne querelle pas ses outils'}, {'score': 3.405615416340879e-07, 'token': 10075, 'token_str': 'fait', 'sequence': 'bon ouvrier nefait pas ses outils'}]\n",
      "20                                        [{'score': 6.107836088631302e-05, 'token': 41, 'token_str': 'est', 'sequence': 'pour le fou, c’est tous les jours fête'}, {'score': 1.6257043000678095e-07, 'token': 80, 'token_str': 'es', 'sequence': 'pour le fou, c’es tous les jours fête'}]\n",
      "21                                                       [{'score': 4.6256518544396386e-06, 'token': 2821, 'token_str': 'faire', 'sequence': 'faire et plaire, sont deux'}, {'score': 2.2369331986737961e-07, 'token': 1755, 'token_str': 'dire', 'sequence': 'dire et plaire, sont deux'}]\n",
      "22                                                             [{'score': 5.904963836655952e-05, 'token': 2821, 'token_str': 'faire', 'sequence': 'dire etfaire , sont deux'}, {'score': 5.502131443790859e-06, 'token': 1755, 'token_str': 'dire', 'sequence': 'dire etdire , sont deux'}]\n",
      "23                                                          [{'score': 1.2044864661220345e-06, 'token': 2821, 'token_str': 'faire', 'sequence': 'dire et plaire,faire deux'}, {'score': 7.389595566564822e-07, 'token': 1755, 'token_str': 'dire', 'sequence': 'dire et plaire,dire deux'}]\n",
      "24                                                          [{'score': 5.175330898055108e-06, 'token': 1755, 'token_str': 'dire', 'sequence': 'dire et faire, sont deux'}, {'score': 1.4810428865530412e-06, 'token': 2821, 'token_str': 'faire', 'sequence': 'faire et faire, sont deux'}]\n",
      "25                                                        [{'score': 1.862357237314427e-07, 'token': 2821, 'token_str': 'faire', 'sequence': 'manger etfaire , sont deux'}, {'score': 4.4232564277990605e-09, 'token': 1755, 'token_str': 'dire', 'sequence': 'manger etdire , sont deux'}]\n",
      "26                                                        [{'score': 4.442603767529363e-06, 'token': 2821, 'token_str': 'faire', 'sequence': 'manger et faire,faire deux'}, {'score': 1.5201501355477376e-06, 'token': 1755, 'token_str': 'dire', 'sequence': 'manger et faire,dire deux'}]\n",
      "27                                    [{'score': 9.037238868359054e-08, 'token': 4587, 'token_str': 'prévenir', 'sequence': 'mieux prévenir prévenir que courir'}, {'score': 3.771550183273575e-09, 'token': 12808, 'token_str': 'guérir', 'sequence': 'mieux guérir prévenir que courir'}]\n",
      "28                                            [{'score': 0.005552957765758038, 'token': 4587, 'token_str': 'prévenir', 'sequence': 'mieux vaut prévenir que courir'}, {'score': 0.00016227307787630707, 'token': 12808, 'token_str': 'guérir', 'sequence': 'mieux vaut guérir que courir'}]\n",
      "29                                          [{'score': 0.9995613694190979, 'token': 12808, 'token_str': 'guérir', 'sequence': 'mieux vaut prévenir que guérir'}, {'score': 1.8127741441276157e-07, 'token': 4587, 'token_str': 'prévenir', 'sequence': 'mieux vaut prévenir que prévenir'}]\n",
      "30                                        [{'score': 3.625130640116936e-09, 'token': 4587, 'token_str': 'prévenir', 'sequence': 'mieux prévenir dormir que guérir'}, {'score': 1.365171642397911e-09, 'token': 12808, 'token_str': 'guérir', 'sequence': 'mieux guérir dormir que guérir'}]\n",
      "31                                               [{'score': 0.9947561025619507, 'token': 4587, 'token_str': 'prévenir', 'sequence': 'mieux vaut prévenir que guérir'}, {'score': 6.313913036137819e-05, 'token': 12808, 'token_str': 'guérir', 'sequence': 'mieux vaut guérir que guérir'}]\n",
      "32                                           [{'score': 0.0033772513270378113, 'token': 12808, 'token_str': 'guérir', 'sequence': 'mieux vaut dormir que guérir'}, {'score': 0.00043162325164303184, 'token': 4587, 'token_str': 'prévenir', 'sequence': 'mieux vaut dormir que prévenir'}]\n",
      "33                                      [{'score': 3.8544028939213604e-05, 'token': 16689, 'token_str': 'nuire', 'sequence': 'à qui dieu nuire , nul ne peut être'}, {'score': 2.4937327225416084e-07, 'token': 761, 'token_str': 'aide', 'sequence': 'à qui dieuaide , nul ne peut être'}]\n",
      "34                                          [{'score': 1.1404957689364892e-07, 'token': 16689, 'token_str': 'nuire', 'sequence': 'à qui dieu aide, nul ne nuire être'}, {'score': 9.64435753481041e-10, 'token': 761, 'token_str': 'aide', 'sequence': 'à qui dieu aide, nul neaide être'}]\n",
      "35                                           [{'score': 0.009052690118551254, 'token': 16689, 'token_str': 'nuire', 'sequence': 'à qui dieu aide, nul ne peut nuire'}, {'score': 2.620355701310473e-07, 'token': 761, 'token_str': 'aide', 'sequence': 'à qui dieu aide, nul ne peutaide'}]\n",
      "36                                     [{'score': 0.0002077389508485794, 'token': 16689, 'token_str': 'nuire', 'sequence': 'à qui dieu nuire , nul ne peut nuire'}, {'score': 1.0850654916794156e-06, 'token': 761, 'token_str': 'aide', 'sequence': 'à qui dieuaide , nul ne peut nuire'}]\n",
      "37                                       [{'score': 1.7771618843198667e-07, 'token': 16689, 'token_str': 'nuire', 'sequence': 'à qui dieu veut, nul ne nuire nuire'}, {'score': 9.717957549781886e-10, 'token': 761, 'token_str': 'aide', 'sequence': 'à qui dieu veut, nul neaide nuire'}]\n",
      "38                                           [{'score': 0.003954420797526836, 'token': 16689, 'token_str': 'nuire', 'sequence': 'à qui dieu veut, nul ne peut nuire'}, {'score': 4.331710101723729e-09, 'token': 761, 'token_str': 'aide', 'sequence': 'à qui dieu veut, nul ne peutaide'}]\n",
      "39                                             [{'score': 1.3616697991380988e-08, 'token': 4294, 'token_str': 'boire', 'sequence': 'il boire le faire pour le croire'}, {'score': 9.483422935829822e-09, 'token': 1419, 'token_str': 'voir', 'sequence': 'ilvoir le faire pour le croire'}]\n",
      "40                                                [{'score': 0.0003781351842917502, 'token': 4294, 'token_str': 'boire', 'sequence': 'il faut le boire pour le croire'}, {'score': 6.366212232933322e-07, 'token': 1419, 'token_str': 'voir', 'sequence': 'il faut levoir pour le croire'}]\n",
      "41                                                 [{'score': 3.974356877733953e-05, 'token': 4294, 'token_str': 'boire', 'sequence': 'il faut le faire pour le boire'}, {'score': 2.9104369332344504e-06, 'token': 1419, 'token_str': 'voir', 'sequence': 'il faut le faire pour levoir'}]\n",
      "42                                           [{'score': 3.965249959492212e-07, 'token': 1757, 'token_str': 'croire', 'sequence': 'il croire le voir pour le saisir'}, {'score': 1.805837435142621e-08, 'token': 4294, 'token_str': 'boire', 'sequence': 'il boire le voir pour le saisir'}]\n",
      "43                                            [{'score': 0.000658117700368166, 'token': 1757, 'token_str': 'croire', 'sequence': 'il faut le croire pour le saisir'}, {'score': 0.0003569422697182745, 'token': 4294, 'token_str': 'boire', 'sequence': 'il faut le boire pour le saisir'}]\n",
      "44                                                [{'score': 0.004395443480461836, 'token': 1757, 'token_str': 'croire', 'sequence': 'il faut le voir pour le croire'}, {'score': 0.0001390691613778472, 'token': 4294, 'token_str': 'boire', 'sequence': 'il faut le voir pour le boire'}]\n",
      "45        [{'score': 0.0007688876357860863, 'token': 3615, 'token_str': 'vend', 'sequence': 'on ne vend pas le poisson qui est encore dans la mer'}, {'score': 8.550640018256672e-08, 'token': 3249, 'token_str': 'dit', 'sequence': 'on nedit pas le poisson qui est encore dans la mer'}]\n",
      "46    [{'score': 1.0747544365585782e-05, 'token': 3615, 'token_str': 'vend', 'sequence': 'on ne mord pas le poisson qui vend encore dans la mer'}, {'score': 1.9427380593128873e-08, 'token': 3249, 'token_str': 'dit', 'sequence': 'on ne mord pas le poisson quidit encore dans la mer'}]\n",
      "47     [{'score': 9.503001820121426e-06, 'token': 41, 'token_str': 'est', 'sequence': 'on neest pas le poisson qui navigue encore dans la mer'}, {'score': 7.2512868598551e-08, 'token': 2860, 'token_str': 'nage', 'sequence': 'on nenage pas le poisson qui navigue encore dans la mer'}]\n",
      "48       [{'score': 1.8495591575629078e-05, 'token': 41, 'token_str': 'est', 'sequence': 'on ne vend pas le poisson quiest encore dans la mer'}, {'score': 5.3410595057812316e-08, 'token': 2860, 'token_str': 'nage', 'sequence': 'on ne vend pas le poisson quinage encore dans la mer'}]\n",
      "49                                                  [{'score': 0.0013441960327327251, 'token': 18287, 'token_str': 'respire', 'sequence': 'le poisson respire par la tête'}, {'score': 3.504602500470355e-05, 'token': 24, 'token_str': 'pour', 'sequence': 'le poisson pour par la tête'}]\n",
      "Name: predictions, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # Show full content of cells\n",
    "print(masked_df['predictions'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13c85b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ground_truth                       masked_sentence  \\\n",
      "0  a beau mentir qui vient de loin   <mask> beau mentir qui part de loin   \n",
      "1  a beau mentir qui vient de loin        a beau <mask> qui part de loin   \n",
      "2  a beau mentir qui vient de loin      a beau mentir qui <mask> de loin   \n",
      "3  a beau mentir qui vient de loin  <mask> beau dormir qui vient de loin   \n",
      "4  a beau mentir qui vient de loin       a beau <mask> qui vient de loin   \n",
      "5  a beau mentir qui vient de loin      a beau dormir qui <mask> de loin   \n",
      "6        l’occasion fait le larron           l’occasion <mask> le larron   \n",
      "7       aide-toi, le ciel t’aidera          endors-toi, le ciel t’aidera   \n",
      "8       aide-toi, le ciel t’aidera          endors-toi, le ciel t’aidera   \n",
      "9       aide-toi, le ciel t’aidera          endors-toi, le ciel t’<mask>   \n",
      "\n",
      "          word_list final_prediction  \\\n",
      "0  [vient, revient]          revient   \n",
      "1  [vient, revient]          revient   \n",
      "2  [vient, revient]          revient   \n",
      "3  [partir, mentir]           partir   \n",
      "4  [partir, mentir]           partir   \n",
      "5  [partir, mentir]           partir   \n",
      "6  [fait, occasion]         occasion   \n",
      "7     [bouge, aide]             None   \n",
      "8     [bouge, aide]             None   \n",
      "9     [bouge, aide]            bouge   \n",
      "\n",
      "                                                                                                                                                                                                                                                  predictions  \\\n",
      "0    [{'score': 5.756229626285858e-08, 'token': 2151, 'token_str': 'revient', 'sequence': 'revient beau mentir qui part de loin'}, {'score': 4.6352996996290585e-09, 'token': 17068, 'token_str': 'vient', 'sequence': 'vient beau mentir qui part de loin'}]   \n",
      "1              [{'score': 1.6705618691048585e-05, 'token': 2151, 'token_str': 'revient', 'sequence': 'a beau revient qui part de loin'}, {'score': 4.7252122215013515e-08, 'token': 17068, 'token_str': 'vient', 'sequence': 'a beauvient qui part de loin'}]   \n",
      "2              [{'score': 0.09831991046667099, 'token': 2151, 'token_str': 'revient', 'sequence': 'a beau mentir qui revient de loin'}, {'score': 8.770224724230502e-08, 'token': 17068, 'token_str': 'vient', 'sequence': 'a beau mentir quivient de loin'}]   \n",
      "3  [{'score': 3.5203133847971912e-06, 'token': 350, 'token_str': 'partir', 'sequence': 'partir beau dormir qui vient de loin'}, {'score': 2.0743095774378162e-07, 'token': 15839, 'token_str': 'mentir', 'sequence': 'mentir beau dormir qui vient de loin'}]   \n",
      "4             [{'score': 0.00037340749986469746, 'token': 350, 'token_str': 'partir', 'sequence': 'a beau partir qui vient de loin'}, {'score': 2.420452619844582e-05, 'token': 15839, 'token_str': 'mentir', 'sequence': 'a beau mentir qui vient de loin'}]   \n",
      "5           [{'score': 0.00019404859631322324, 'token': 350, 'token_str': 'partir', 'sequence': 'a beau dormir qui partir de loin'}, {'score': 1.685952383922995e-06, 'token': 15839, 'token_str': 'mentir', 'sequence': 'a beau dormir qui mentir de loin'}]   \n",
      "6                       [{'score': 2.846029190095578e-07, 'token': 690, 'token_str': 'occasion', 'sequence': 'l’occasionoccasion le larron'}, {'score': 2.0510158904585296e-08, 'token': 10075, 'token_str': 'fait', 'sequence': 'l’occasionfait le larron'}]   \n",
      "7                                                                                                                                                                                                                   No mask_token (<mask>) found on the input   \n",
      "8                                                                                                                                                                                                                   No mask_token (<mask>) found on the input   \n",
      "9                         [{'score': 1.208062030855217e-06, 'token': 6337, 'token_str': 'bouge', 'sequence': 'endors-toi, le ciel t’ bouge'}, {'score': 2.9202445261944376e-07, 'token': 761, 'token_str': 'aide', 'sequence': 'endors-toi, le ciel t’aide'}]   \n",
      "\n",
      "           original_masked_proverb  index  \n",
      "0   a beau mentir qui part de loin      0  \n",
      "1   a beau mentir qui part de loin      0  \n",
      "2   a beau mentir qui part de loin      0  \n",
      "3  a beau dormir qui vient de loin      1  \n",
      "4  a beau dormir qui vient de loin      1  \n",
      "5  a beau dormir qui vient de loin      1  \n",
      "6       l’occasion forge le larron      2  \n",
      "7     endors-toi, le ciel t’aidera      3  \n",
      "8     endors-toi, le ciel t’aidera      3  \n",
      "9     endors-toi, le ciel t’aidera      3  \n"
     ]
    }
   ],
   "source": [
    "# extract the word with the highest score\n",
    "def get_highest_score_prediction(predictions):\n",
    "    if isinstance(predictions, list) and len(predictions) > 0:\n",
    "        best_prediction = max(predictions, key=lambda x: x['score'])\n",
    "        return best_prediction['token_str']  # Return token (i.e. word)\n",
    "    return None  # none if pred are empty or invalid\n",
    "\n",
    "masked_df['final_prediction'] = masked_df['predictions'].apply(get_highest_score_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37707717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ground_truth                       masked_sentence  \\\n",
      "0  a beau mentir qui vient de loin   <mask> beau mentir qui part de loin   \n",
      "1  a beau mentir qui vient de loin        a beau <mask> qui part de loin   \n",
      "2  a beau mentir qui vient de loin      a beau mentir qui <mask> de loin   \n",
      "3  a beau mentir qui vient de loin  <mask> beau dormir qui vient de loin   \n",
      "4  a beau mentir qui vient de loin       a beau <mask> qui vient de loin   \n",
      "5  a beau mentir qui vient de loin      a beau dormir qui <mask> de loin   \n",
      "6        l’occasion fait le larron           l’occasion <mask> le larron   \n",
      "7       aide-toi, le ciel t’aidera          endors-toi, le ciel t’aidera   \n",
      "8       aide-toi, le ciel t’aidera          endors-toi, le ciel t’aidera   \n",
      "9       aide-toi, le ciel t’aidera          endors-toi, le ciel t’<mask>   \n",
      "\n",
      "          word_list final_prediction  \\\n",
      "0  [vient, revient]          revient   \n",
      "1  [vient, revient]          revient   \n",
      "2  [vient, revient]          revient   \n",
      "3  [partir, mentir]           partir   \n",
      "4  [partir, mentir]           partir   \n",
      "5  [partir, mentir]           partir   \n",
      "6  [fait, occasion]         occasion   \n",
      "7     [bouge, aide]             None   \n",
      "8     [bouge, aide]             None   \n",
      "9     [bouge, aide]            bouge   \n",
      "\n",
      "                                                                                                                                                                                                                                                  predictions  \\\n",
      "0    [{'score': 5.756229626285858e-08, 'token': 2151, 'token_str': 'revient', 'sequence': 'revient beau mentir qui part de loin'}, {'score': 4.6352996996290585e-09, 'token': 17068, 'token_str': 'vient', 'sequence': 'vient beau mentir qui part de loin'}]   \n",
      "1              [{'score': 1.6705618691048585e-05, 'token': 2151, 'token_str': 'revient', 'sequence': 'a beau revient qui part de loin'}, {'score': 4.7252122215013515e-08, 'token': 17068, 'token_str': 'vient', 'sequence': 'a beauvient qui part de loin'}]   \n",
      "2              [{'score': 0.09831991046667099, 'token': 2151, 'token_str': 'revient', 'sequence': 'a beau mentir qui revient de loin'}, {'score': 8.770224724230502e-08, 'token': 17068, 'token_str': 'vient', 'sequence': 'a beau mentir quivient de loin'}]   \n",
      "3  [{'score': 3.5203133847971912e-06, 'token': 350, 'token_str': 'partir', 'sequence': 'partir beau dormir qui vient de loin'}, {'score': 2.0743095774378162e-07, 'token': 15839, 'token_str': 'mentir', 'sequence': 'mentir beau dormir qui vient de loin'}]   \n",
      "4             [{'score': 0.00037340749986469746, 'token': 350, 'token_str': 'partir', 'sequence': 'a beau partir qui vient de loin'}, {'score': 2.420452619844582e-05, 'token': 15839, 'token_str': 'mentir', 'sequence': 'a beau mentir qui vient de loin'}]   \n",
      "5           [{'score': 0.00019404859631322324, 'token': 350, 'token_str': 'partir', 'sequence': 'a beau dormir qui partir de loin'}, {'score': 1.685952383922995e-06, 'token': 15839, 'token_str': 'mentir', 'sequence': 'a beau dormir qui mentir de loin'}]   \n",
      "6                       [{'score': 2.846029190095578e-07, 'token': 690, 'token_str': 'occasion', 'sequence': 'l’occasionoccasion le larron'}, {'score': 2.0510158904585296e-08, 'token': 10075, 'token_str': 'fait', 'sequence': 'l’occasionfait le larron'}]   \n",
      "7                                                                                                                                                                                                                   No mask_token (<mask>) found on the input   \n",
      "8                                                                                                                                                                                                                   No mask_token (<mask>) found on the input   \n",
      "9                         [{'score': 1.208062030855217e-06, 'token': 6337, 'token_str': 'bouge', 'sequence': 'endors-toi, le ciel t’ bouge'}, {'score': 2.9202445261944376e-07, 'token': 761, 'token_str': 'aide', 'sequence': 'endors-toi, le ciel t’aide'}]   \n",
      "\n",
      "           original_masked_proverb  index  \n",
      "0   a beau mentir qui part de loin      0  \n",
      "1   a beau mentir qui part de loin      0  \n",
      "2   a beau mentir qui part de loin      0  \n",
      "3  a beau dormir qui vient de loin      1  \n",
      "4  a beau dormir qui vient de loin      1  \n",
      "5  a beau dormir qui vient de loin      1  \n",
      "6       l’occasion forge le larron      2  \n",
      "7     endors-toi, le ciel t’aidera      3  \n",
      "8     endors-toi, le ciel t’aidera      3  \n",
      "9     endors-toi, le ciel t’aidera      3  \n"
     ]
    }
   ],
   "source": [
    "# Reorder cols for better readability\n",
    "masked_df = masked_df[['ground_truth', 'masked_sentence', 'word_list', 'final_prediction', 'predictions', 'original_masked_proverb', 'index']]\n",
    "print(masked_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247b5ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ground_truth                   masked_sentence  \\\n",
      "0  a beau mentir qui vient de loin  a beau mentir qui <mask> de loin   \n",
      "1  a beau mentir qui vient de loin   a beau <mask> qui vient de loin   \n",
      "2        l’occasion fait le larron       l’occasion <mask> le larron   \n",
      "3       aide-toi, le ciel t’aidera      endors-toi, le ciel t’<mask>   \n",
      "4       aide-toi, le ciel t’aidera        aide-toi, le ciel t’<mask>   \n",
      "\n",
      "          word_list final_prediction  \\\n",
      "0  [vient, revient]          revient   \n",
      "1  [partir, mentir]           partir   \n",
      "2  [fait, occasion]         occasion   \n",
      "3     [bouge, aide]            bouge   \n",
      "4    [aidera, aide]           aidera   \n",
      "\n",
      "                                                                                                                                                                                                                                       predictions  \\\n",
      "0   [{'score': 0.09831991046667099, 'token': 2151, 'token_str': 'revient', 'sequence': 'a beau mentir qui revient de loin'}, {'score': 8.770224724230502e-08, 'token': 17068, 'token_str': 'vient', 'sequence': 'a beau mentir quivient de loin'}]   \n",
      "1  [{'score': 0.00037340749986469746, 'token': 350, 'token_str': 'partir', 'sequence': 'a beau partir qui vient de loin'}, {'score': 2.420452619844582e-05, 'token': 15839, 'token_str': 'mentir', 'sequence': 'a beau mentir qui vient de loin'}]   \n",
      "2            [{'score': 2.846029190095578e-07, 'token': 690, 'token_str': 'occasion', 'sequence': 'l’occasionoccasion le larron'}, {'score': 2.0510158904585296e-08, 'token': 10075, 'token_str': 'fait', 'sequence': 'l’occasionfait le larron'}]   \n",
      "3              [{'score': 1.208062030855217e-06, 'token': 6337, 'token_str': 'bouge', 'sequence': 'endors-toi, le ciel t’ bouge'}, {'score': 2.9202445261944376e-07, 'token': 761, 'token_str': 'aide', 'sequence': 'endors-toi, le ciel t’aide'}]   \n",
      "4                  [{'score': 0.49035122990608215, 'token': 11611, 'token_str': 'aidera', 'sequence': 'aide-toi, le ciel t’ aidera'}, {'score': 5.284612598188687e-06, 'token': 761, 'token_str': 'aide', 'sequence': 'aide-toi, le ciel t’aide'}]   \n",
      "\n",
      "           original_masked_proverb  index  \n",
      "0   a beau mentir qui part de loin      0  \n",
      "1  a beau dormir qui vient de loin      1  \n",
      "2       l’occasion forge le larron      2  \n",
      "3     endors-toi, le ciel t’aidera      3  \n",
      "4         aide-toi, le ciel t’aura      4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/1qy7d39n5t728w232c3qvq8m0000gn/T/ipykernel_34520/2929172703.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_df = masked_df.groupby('index').apply(get_highest_score_row).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# get highest scoring prediction for each index group\n",
    "def get_highest_score_row(group):\n",
    "    # only valid predictions\n",
    "    valid_predictions = group[group['predictions'].apply(lambda x: isinstance(x, list))]\n",
    "    if valid_predictions.empty:\n",
    "        return None  # if no valid prediction exists\n",
    "\n",
    "    # max score row\n",
    "    best_row = valid_predictions.loc[valid_predictions['predictions'].apply(\n",
    "        lambda preds: max([p['score'] for p in preds] if isinstance(preds, list) else [0])\n",
    "    ).idxmax()]\n",
    "    return best_row\n",
    "\n",
    "final_df = masked_df.groupby('index').apply(get_highest_score_row).reset_index(drop=True)\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "372d1dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             ground_truth  \\\n",
      "0                                         a beau mentir qui vient de loin   \n",
      "1                                         a beau mentir qui vient de loin   \n",
      "2                                               l’occasion fait le larron   \n",
      "3                                              aide-toi, le ciel t’aidera   \n",
      "4                                              aide-toi, le ciel t’aidera   \n",
      "5                                         ce que femme veut, dieu le veut   \n",
      "6                                         ce que femme veut, dieu le veut   \n",
      "7                                       bien mal acquis ne profite jamais   \n",
      "8                                  bon ouvrier ne querelle pas ses outils   \n",
      "9                                  pour le fou, c’est tous les jours fête   \n",
      "10                                               dire et faire, sont deux   \n",
      "11                                               dire et faire, sont deux   \n",
      "12                                         mieux vaut prévenir que guérir   \n",
      "13                                         mieux vaut prévenir que guérir   \n",
      "14                                     à qui dieu aide, nul ne peut nuire   \n",
      "15                                     à qui dieu aide, nul ne peut nuire   \n",
      "16                                         il faut le voir pour le croire   \n",
      "17                                         il faut le voir pour le croire   \n",
      "18                   on ne vend pas le poisson qui est encore dans la mer   \n",
      "19                   on ne vend pas le poisson qui est encore dans la mer   \n",
      "20                                         le poisson pourrit par la tête   \n",
      "21         couche-toi plutôt sans souper, que de te lever avec des dettes   \n",
      "22         couche-toi plutôt sans souper, que de te lever avec des dettes   \n",
      "23  les montagnes ne se rencontrent point, mais les hommes se rencontrent   \n",
      "24  les montagnes ne se rencontrent point, mais les hommes se rencontrent   \n",
      "25                                manger peu, chasse beaucoup de maladies   \n",
      "\n",
      "                                                        predicted_proverb  \n",
      "0                                       a beau mentir qui revient de loin  \n",
      "1                                         a beau partir qui vient de loin  \n",
      "2                                           l’occasion occasion le larron  \n",
      "3                                             endors-toi, le ciel t’bouge  \n",
      "4                                              aide-toi, le ciel t’aidera  \n",
      "5                                         ce que femme veut, dieu le veut  \n",
      "6                                         ce que femme veut, dieu le veut  \n",
      "7                                       bien mal acquis ne profite jamais  \n",
      "8                                  bon ouvrier ne querelle pas ses outils  \n",
      "9                                  pour le fou, c’est tous les jours fête  \n",
      "10                                               dire et faire, sont deux  \n",
      "11                                               dire et faire, sont deux  \n",
      "12                                         mieux vaut prévenir que guérir  \n",
      "13                                         mieux vaut prévenir que guérir  \n",
      "14                                     à qui dieu aide, nul ne peut nuire  \n",
      "15                                     à qui dieu veut, nul ne peut nuire  \n",
      "16                                        il faut le boire pour le croire  \n",
      "17                                         il faut le voir pour le croire  \n",
      "18                   on ne vend pas le poisson qui est encore dans la mer  \n",
      "19                   on ne vend pas le poisson qui est encore dans la mer  \n",
      "20                                         le poisson respire par la tête  \n",
      "21    reposecouchetoi plutôt sans souper, que de te lever avec des dettes  \n",
      "22         couche-toi plutôt sans souper, que de te lever avec des dettes  \n",
      "23  les montagnes ne se rencontrent point, mais les hommes se rencontrent  \n",
      "24  les montagnes ne se rencontrent point, mais les hommes se rencontrent  \n",
      "25                                 parle peu, chasse beaucoup de maladies  \n"
     ]
    }
   ],
   "source": [
    "# construct the predicted proverb\n",
    "def construct_predicted_proverb(row):\n",
    "    if pd.isna(row['final_prediction']) or '<mask>' not in row['masked_sentence']:\n",
    "        return 'CHECK ME AGAIN' # Return as is if no valid prediction or no mask present\n",
    "    return row['masked_sentence'].replace('<mask>', row['final_prediction'])\n",
    "\n",
    "# Create predicted proverb column\n",
    "final_df['predicted_proverb'] = final_df.apply(construct_predicted_proverb, axis=1)\n",
    "\n",
    "print(final_df[['ground_truth', 'predicted_proverb']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf550d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.38%\n",
      "Correct Predictions: 17/26\n"
     ]
    }
   ],
   "source": [
    "# Calculate Prediction Accuracy\n",
    "final_df['is_correct'] = final_df['predicted_proverb'] == df['Proverb']\n",
    "accuracy_score = final_df['is_correct'].mean() * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score:.2f}%\")\n",
    "\n",
    "num_correct = final_df['is_correct'].sum()\n",
    "total_observations = len(final_df)\n",
    "print(f\"Correct Predictions: {num_correct}/{total_observations}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd160430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}, {'score': 0.17374156415462494, 'token': 6256, 'token_str': 'Très', 'sequence': 'Très peu, chasse beaucoup de maladies'}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b755d014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5720e938",
   "metadata": {},
   "source": [
    "## Section 4 - Expérimentations et analyse de résultats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1aaaf5",
   "metadata": {},
   "source": [
    "L'approche générale que nous avons choisie pour la tâche 3 consiste en 5 parties :\n",
    "\n",
    "#### 1. POS Tagging\n",
    "Nous avons utilisé le modèle gilf/french-camembert-postag-model pour effectuer le POS Tagging. Parfois, le modèle retourne le mot correct qui doit être remplacé, parfois il retourne plus de verbes (par exemple, dans le premier proverbe masqué \"a beau mentir qui vient de loin\", le modèle retourne trois verbes : \"a\", \"mentir\" et \"vient\"). Tous les verbes sont conservés pour être testés dans l'étape de prédiction du verbe masqué. Le modèle réussit à trouver la plupart des verbes, mais dans certains cas, il identifie d'autres termes incorrectement. Par exemple, dans le proverbe \"aide-toi, le ciel t'aura\", il identifie le trait d'union comme un verbe. Cette erreur ne devrait pas être trop importante puisque le deuxième modèle devrait identifier que \"aideaidetoi\" (le trait d'union remplacé par \"aide\") n'a aucun sens et donnera un très petit score à ce terme.\n",
    "\n",
    "#### 2. Création d'un nouveau DataFrame pandas avec une ligne par verbe détecté (par POS Tagging) et un verbe masqué\n",
    "Étant donné que nous savons qu'un seul mot est modifié par ligne, nous avons choisi de créer un nouveau DataFrame pandas qui contient une ligne par verbe détecté (par ligne originale). Ainsi, si nous prenons le premier exemple, le nouveau DataFrame a 3 lignes pour le proverbe \"a beau mentir qui vient de loin\". Dans chaque ligne, un des verbes est masqué :\n",
    "\n",
    "a) <mask> beau mentir qui vient de loin\n",
    "\n",
    "b) a beau <mask> qui vient de loin \n",
    "\n",
    "c) a beau mentir qui <mask> de loin\n",
    "\n",
    "#### 3. Prédiction du verbe masqué pour chaque ligne\n",
    "Nous utilisons le modèle camembert/camembert-base-oscar-4gb pour prédire le mot masqué en utilisant la liste des verbes donnés. Le modèle retourne des scores pour chaque mot candidat. Pour l'exemple précédent, 2 scores par ligne sont retournés, donc au total 6 scores pour le premier proverbe avec les trois mots masqués. Nous choisissons entre les 2 scores par verbe masqué par ligne le verbe avec le score le plus grand.\n",
    "\n",
    "Pour faire l'inférence, nous utilisons le pipeline de \"fill-mask\" de Transformers. Le modèle retourné permet de spécifier des _targets_, c'est-à-dire les mots à utiliser pour le masque. Des avertissements indiquent que tous les mots ne font pas partie du vocabulaire du modèle. Il semblerait que cela soit dû au fait que la tokenisation des _targets_ se fait avec [BERT au lieu de celle fournie par le modèle](https://l.messenger.com/l.php?u=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftransformers%2Fissues%2F19379&h=AT2TNkJEfARZGqrsYbqtytAamnLWh_6ZKRVP9V-uCYlQVYUERuvbbckqWzDEBJ8-KO29FdBrII-Jd5hwxzNaBfXBWu_ZQ5NMnPo1RSq9FGIVo-_9BL9RdcADmbFC7bJwIiyRn0mQKUp0EUI). Nous avons donc testé en fournissant les termes préfixés par \"_\" qui semble être le format du vocabulaire de Camembert. Ainsi, seulement un mot, \"_pourri\", ne se trouve pas dans le vocabulaire. Cependant, il semblerait que le terme utilisé pour remplacer le mot non préfixé de \"_\" soit efficace puisque le changement n'a pas permis d'améliorer les résultats. Au contraire, les performances étaient inférieures en préfixant les mots, puisque le mot \"_pourrit\" qui n'est pas dans le vocabulaire est remplacé par \"_pour\", ce qui n'a pas la même signification et cause le modèle de se tromper sur le proverbe avec ce terme.\n",
    "\n",
    "#### 4. Sélection du score le plus élevé pour choisir le mot masqué et le remplacer\n",
    "Dans la partie suivante du code, nous comparons les scores entre les lignes qui correspondent au même proverbe (nous avons introduit un indice auparavant). Encore une fois, nous choisissons le mot avec le score le plus élevé pour le remplacer. Ainsi, ici, nous choisissons le mot qui est remplacé basé sur le score. Nous suivons l'hypothèse que le bon mot candidat sera meilleur dans le bon contexte correct que ce mot dans les autres contextes ou l'autre mot dans tous les contextes.\n",
    "\n",
    "#### 5. Comparaison de la prédiction avec la vérité\n",
    "Finalement, nous remplaçons le token <mask> par le mot prédit dans le proverbe et le comparons avec le vrai proverbe. Le modèle réussit à prédire correctement 17 proverbes sur 26, ce qui correspond à une précision de 65,38 %.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb078efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a287a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fd2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b046259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7e9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a13ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f99003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
