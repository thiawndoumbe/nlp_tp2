{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tâche #1 : Classification d'incidents avec des modèles *Transformers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On reprend, comme au premier travail, le thème de la classification de descriptions d’incidents. Cependant, la définition des classes est différente pour ce travail et de nouveaux jeux de données ont été produits. Le corpus de textes contient 3 partitions : \n",
    "-\tUn fichier d’entraînement -  *data/incidents_train.json*\n",
    "-\tUn fichier de validation -  *data/incidents_dev.json*\n",
    "-\tUn fichier de test - *data/incidents_test.json*\n",
    " \n",
    "Utilisez la librairie *HuggingFace* pour accomplir cette tâche. On vous demande plus spécifiquement d’utiliser 2 modèles: le modèle *bert-base-uncased* et un autre modèle de votre choix. \n",
    "\n",
    "Les consignes pour cette tâche sont: \n",
    "- Nom du notebook : *t1_classification.ipynb* (ce notebook)\n",
    "- Tokenisation : Celle fournie par les tokeniseurs accompagnant les modèles transformers. \n",
    "- Plongements de mots : Ceux du modèle transformer. \n",
    "- Normalisation : Lettre en minuscule pour Bert (rien à faire, le tokenizer s’en occupe). Aucune contrainte pour le 2e modèle mais il est préférable de ne pas altérer le texte (sauf minuscule). \n",
    "- Choix du 2e transformer: Un modèle encodeur préentraîné pour l’anglais ou multilingue. Le modèle ne doit pas être une variante de Bert (p. ex. DistilBert). Me consulter en cas de doute.\n",
    "- Entraînement : Un affinage (*fine-tuning*) du modèle, pas de préentraînement demandé (*no further pretraining*). \n",
    "- Analyse : Présentez clairement vos résultats et faites-en l’analyse. Comparez les résultats obtenus avec les 2 modèles.    \n",
    "\n",
    "Vous pouvez ajouter au *notebook* toutes les cellules dont vous avez besoin pour votre code, vos explications ou la présentation de vos résultats. Vous pouvez également ajouter des sous-sections (par ex. des sous-sections 1.1, 1.2 etc.) si cela améliore la lisibilité.\n",
    "\n",
    "Notes :\n",
    "- Évitez les bouts de code trop longs ou trop complexes. Par exemple, il est difficile de comprendre 4-5 boucles ou conditions imbriquées. Si c'est le cas, définissez des sous-fonctions pour refactoriser et simplifier votre code. \n",
    "- Expliquez sommairement votre démarche.\n",
    "- Expliquez les choix que vous faites au niveau de la programmation et des modèles (si non trivial).\n",
    "- Analyser vos résultats. Indiquez ce que vous observez, si c'est bon ou non, si c'est surprenant, etc. \n",
    "- Une analyse quantitative et qualitative d'erreurs est intéressante et permet de mieux comprendre le comportement d'un modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Création du jeu de données (*les 3 partitions du dataset*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_data(filename):\n",
    "    with open(filename, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notre collaboration avec Google Colab a été motivée par le coût élevé de l'entraînement des modèles transformers et la nécessité d'un GPU performant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/Documents/ulaval/nlp/tp2/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data= {\"train\": \"incidents_train.json\", \"dev\": \"incidents_dev.json\",\"test\": \"incidents_test.json\"}\n",
    "data = load_dataset(\"json\", data_files=data, data_dir=r\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tokenizer et les embeddings de bert-base-uncased sont utilisés ici ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 531/531 [00:00<00:00, 9010.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' At approximately 8:50 a.m. on October 29  1997  Employee #1 was painting a  single story house at 2657 7th Ave  Sacramento  CA. He was caulking around the  peak of the roof line on the west side of the house  20 ft above the ground.  He was working off of a 24 ft aluminum extension ladder so that his feet were  approximately 12 to 13 feet above the ground. Employee #1 fell and suffered a  concussion and two dislocated discs in his lower back and was hospitalized.  The ladder was not secured to prevent movement.                                 ', 'label': '5', 'input_ids': [101, 2012, 3155, 1022, 1024, 2753, 1037, 1012, 1049, 1012, 2006, 2255, 2756, 2722, 7904, 1001, 1015, 2001, 4169, 1037, 2309, 2466, 2160, 2012, 20549, 2581, 5504, 13642, 11932, 6187, 1012, 2002, 2001, 6187, 5313, 6834, 2105, 1996, 4672, 1997, 1996, 4412, 2240, 2006, 1996, 2225, 2217, 1997, 1996, 2160, 2322, 3027, 2682, 1996, 2598, 1012, 2002, 2001, 2551, 2125, 1997, 1037, 2484, 3027, 13061, 5331, 10535, 2061, 2008, 2010, 2519, 2020, 3155, 2260, 2000, 2410, 2519, 2682, 1996, 2598, 1012, 7904, 1001, 1015, 3062, 1998, 4265, 1037, 23159, 1998, 2048, 4487, 14540, 24755, 3064, 15303, 1999, 2010, 2896, 2067, 1998, 2001, 24735, 1012, 1996, 10535, 2001, 2025, 7119, 2000, 4652, 2929, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def bert_preprocess_function(examples):\n",
    "    return bert_tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_dataset = data.map(bert_preprocess_function, batched=True)\n",
    "print(tokenized_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les labels doivent être convertis en entiers pour l'entraînement, sinon le format str pose un problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in tokenized_dataset.keys():\n",
    "    if 'label' in tokenized_dataset[partition].column_names:\n",
    "        labels = tokenized_dataset[partition]['label']\n",
    "        tokenized_dataset[partition] = tokenized_dataset[partition].remove_columns(\"label\")\n",
    "        tokenized_dataset[partition] = tokenized_dataset[partition].add_column(\"label\", [int(value) for value in labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les réseaux récurrents, il est nécessaire de faire un padding des séquences pour garantir une taille de tenseur équivalente pour chaque entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "dataset_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Création des 2 modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Modèle BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différentes fonctions qui seront utilisées pour évaluer notre modèle sont implantées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy_metric = evaluate.load(\"accuracy\", force_download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_predictions):\n",
    "    preds, true_labels = eval_predictions\n",
    "    predicted_label = np.argmax(preds, axis=1)\n",
    "    return accuracy_metric.compute(predictions=predicted_label, references=true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici les classes sont converties en identifiants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des dictionnaires de correspondance label <-> id\n",
    "nb_classes = len(np.unique(data['train']['label']))\n",
    "id2label = {i: str(i) for i in range(nb_classes)}\n",
    "label2id = {str(i): i for i in range(nb_classes)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisons le GPU  pour entraîner le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device selected: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device selected: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification,TrainingArguments, Trainer\n",
    "\n",
    "bert_uncased_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=nb_classes,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Deuxième modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un autre modèle pré-entraîné est utilisé pour l'anglais : Electra.\n",
    "Le pré-entraînement d'Electra diffère de celui de Bert. Effectivement, l'entraînement préliminaire de ce modèle repose sur une approche adversariale, ce qui permet de déterminer si des mots de la phrase sont des mots réels ou s'ils ont été générés par un modèle génératif. Il y a également une différence entre Electra et Bert car le modèle ne fait pas de NSP pour son pré-entraînement.\n",
    "\n",
    "Les mêmes fonctions et données sont conservées, le tokenizer et le modèle sont simplement remplacés par Electra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_tokenizer = AutoTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n",
    "\n",
    "def electra_preprocess_function(examples):\n",
    "    return electra_tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 531/531 [00:00<00:00, 10832.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "electra_tokenized_data = data.map(electra_preprocess_function, batched=True)\n",
    "for partition in electra_tokenized_data.keys():\n",
    "    labels = electra_tokenized_data[partition]['label']\n",
    "    electra_tokenized_data[partition] = electra_tokenized_data[partition].remove_columns(\"label\")\n",
    "    electra_tokenized_data[partition] = electra_tokenized_data[partition].add_column(\"label\", [int(label) for label in labels])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=electra_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "electra_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google/electra-base-discriminator\", \n",
    "    num_labels=nb_classes, \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entraînement des 2 modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Modèle BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'entraînement, nous avons choisi d'utiliser 3 époques afin d'obtenir de meilleures performances, bien que cela augmente le temps d'entraînement en raison de la complexité du calcul d'attention. Les autres hyperparamètres restent ceux par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/Documents/ulaval/nlp/tp2/venv/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_101672/3465564458.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_instance = Trainer(\n",
      "/home/jonathan/Documents/ulaval/nlp/tp2/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at ../aten/src/ATen/Context.cpp:296.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7425' max='7425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7425/7425 09:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.079400</td>\n",
       "      <td>1.020924</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.813900</td>\n",
       "      <td>0.933403</td>\n",
       "      <td>0.822976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.573300</td>\n",
       "      <td>1.043175</td>\n",
       "      <td>0.832392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7425, training_loss=0.8723962279040404, metrics={'train_runtime': 556.8123, 'train_samples_per_second': 13.335, 'train_steps_per_second': 13.335, 'total_flos': 555967530996570.0, 'train_loss': 0.8723962279040404, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_params = TrainingArguments(\n",
    "    output_dir=\"bert_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False\n",
    "    )\n",
    "\n",
    "trainer_instance = Trainer(\n",
    "    model=bert_uncased_model,\n",
    "    args=training_params,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"dev\"],\n",
    "    tokenizer=bert_tokenizer,\n",
    "    data_collator=dataset_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "\n",
    ")\n",
    "\n",
    "trainer_instance.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deuxième modèle _ Electra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du model Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/Documents/ulaval/nlp/tp2/venv/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_101672/4056485202.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_instance2 = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7425' max='7425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7425/7425 09:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.273400</td>\n",
       "      <td>1.064022</td>\n",
       "      <td>0.696798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.986100</td>\n",
       "      <td>0.986575</td>\n",
       "      <td>0.772128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.802900</td>\n",
       "      <td>1.093056</td>\n",
       "      <td>0.790960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7425, training_loss=1.069408538510101, metrics={'train_runtime': 561.0239, 'train_samples_per_second': 13.235, 'train_steps_per_second': 13.235, 'total_flos': 555967530996570.0, 'train_loss': 1.069408538510101, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_params2= TrainingArguments(\n",
    "    output_dir=\"model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False\n",
    "    )\n",
    "\n",
    "trainer_instance2 = Trainer(\n",
    "    model=electra_model,\n",
    "    args=training_params2,\n",
    "    train_dataset=electra_tokenized_data[\"train\"],\n",
    "    eval_dataset=electra_tokenized_data[\"dev\"],\n",
    "    tokenizer=electra_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "\n",
    ")\n",
    "\n",
    "trainer_instance2.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Évaluation, analyse de résultats et comparaison des 2 modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation  du model BERT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 1.1154084205627441, 'test_accuracy': 0.775894538606403, 'test_runtime': 6.6417, 'test_samples_per_second': 79.949, 'test_steps_per_second': 79.949}\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_instance.predict(tokenized_dataset[\"test\"])\n",
    "print(predictions[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation du model Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 1.1527515649795532, 'test_accuracy': 0.743879472693032, 'test_runtime': 4.6396, 'test_samples_per_second': 114.45, 'test_steps_per_second': 114.45}\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_instance2.predict(electra_tokenized_data[\"test\"])\n",
    "print(predictions[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyse de résultats et comparaison des 2 modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Precision (Precision)\n",
    "    BERT : Grâce à une précision de 77,59% sur le jeu de test après trois époques, BERT met en évidence sa capacité à identifier des relations complexes entre les mots dans le domaine textuel. Les résultats de cette performance  montre que les têtes self-attention permettent vraiment au modèle de comprendre  les contructions et les liens entre les mots, ce qui renforce la capacité du modèle à prédire les classes et a saisir les dépendances à long terme dans les descriptions des incidents. Cette précision est nettement supérieure à celle obtenue avec ELECTRA .\n",
    "\n",
    "    La précision du modèle ELECTRA est de 74,39%, ce qui, même si elle est légèrement inférieure à celle de BERT, demeure compétitive. ELECTRA peut se concentrer plus rapidement sur les relations pertinentes dans les données grâce à une stratégie de pré-entraînement basée sur la discrimination (au lieu du masquage comme pour BERT), ce qui peut améliorer son efficacité .\n",
    "\n",
    "    Conclusion sur la précision : Bien que BERT surpasse ELECTRA en termes de précision, ELECTRA reste performant et pourrait être préféré dans des cas où la vitesse et l'efficacité computationnelle sont des priorités.\n",
    "\n",
    "2. Perte (Test Loss)\n",
    "    En ce qui concerne BERT, la perte de test de 1,115 est un indicateur stable de convergence, ce qui indique que le modèle s'est correctement adapté aux données lors de l'entraînement. Cela laisse entendre que BERT peut gérer les cas complexes et réduire les erreurs de manière plus efficace, même si le nombre d'époques est relativement limité.\n",
    "\n",
    "\n",
    "    Conclusion sur la perte : BERT semble mieux gérer les relations complexes et converge plus efficacement dans ce cas spécifique, tandis qu'ELECTRA, bien qu'efficace, nécessite peut-être plus d'ajustements dans le fine-tuning.\n",
    "\n",
    "3. Vitesse d'Apprentissage et d'Inférence\n",
    "    Vitesse d'apprentissage : Bien que ELECTRA soit réputé pour son efficacité en fine-tuning grâce à son approche de pré-entraînement basée sur la discrimination, dans ce cas, les résultats ne montrent pas de différence notable en termes de vitesse d'apprentissage par rapport à BERT. Cette égalité suggère que les deux modèles ont des performances d'entraînement similaires avec les paramètres choisis.\n",
    "\n",
    "    Vitesse d'inférence : En revanche,  ELECTRA se démarque grâce à sa rapidité d'inférence. Son taux de traitement est de 114,45 échantillons par seconde, ce qui est pratiquement à la fois plus rapide que BERT (qui traite 79,95 échantillons par seconde). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
